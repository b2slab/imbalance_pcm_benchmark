{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from math import ceil\n",
    "import h5py\n",
    "from glob import glob\n",
    "from plotnine import *\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TerminateOnNaN\n",
    "from keras import backend as K \n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.backend import manual_variable_initialization \n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, concatenate, Flatten, Conv1D, BatchNormalization, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela3/imbalance_pcm_benchmark/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "from src.model_functions import *\n",
    "\n",
    "np.random.seed(8)\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_type = \"kinases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paddings = [\"post_padding\", \"pre_padding\", \"mid_padding\", \"ext_padding\", \"strf_padding\",\n",
    "                 \"rnd_padding\", \"zoom_padding\"]\n",
    "# FOLD\n",
    "fold = 0\n",
    "n_epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening HDF5 with data\n",
    "file_h5 = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/compounds_activity.h5\"))\n",
    "f = h5py.File(file_h5, 'r')\n",
    "group = '/activity'\n",
    "table = \"prot_comp\"\n",
    "#shuffling data indices\n",
    "n_samples = len(f[group][table])\n",
    "sample_indices = np.arange(0, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading maximum lengths of proteins and compounds\n",
    "with open(\"\".join((absPath, 'data/prot_max_len.pickle')), \"rb\") as input_file:\n",
    "    max_len_prot = pickle.load(input_file)\n",
    "\n",
    "#Defining protein dictionary    \n",
    "instarget = Target(\"AAA\")\n",
    "prot_dict = instarget.predefining_dict()\n",
    "\n",
    "# Loading the corresponding splitting list\n",
    "file_list = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/splitting_lists/splitting_\", str(fold),\"_list.pickle\"))\n",
    "with open(file_list, \"rb\") as input_file:\n",
    "    splitting_list = pickle.load(input_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "decay_rate = learning_rate/n_epochs\n",
    "adamm = Adam(lr=learning_rate, beta_1=0.1, beta_2=0.001, epsilon=1e-08, decay=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1499, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1499, 64)     5056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1499, 64)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 95936)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 881)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           4796850     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           44100       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            202         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,846,208\n",
      "Trainable params: 4,846,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "# LEFT BLOCK (to analyse amino acid sequences)\n",
    "input_seq = Input(shape=(max_len_prot, len(prot_dict)), dtype='float32')\n",
    "conv_seq = Conv1D(filters=64, padding='same', strides=1, kernel_size=3, activation='relu')(input_seq)\n",
    "dropout_1 = Dropout(0.4)(conv_seq)\n",
    "flatten_seq = Flatten()(dropout_1)#(dense_seq)\n",
    "dense_seq_2 = Dense(50)(flatten_seq)\n",
    "dropout_2 = Dropout(0.4)(dense_seq_2)\n",
    "\n",
    "#RIGHT BRANCH (to analyse fingerprints)\n",
    "input_fps = Input(shape=(881,), dtype='float32')\n",
    "dense_fps = Dense(50)(input_fps)\n",
    "dropout_3 = Dropout(0.4)(dense_fps)\n",
    "#bn_3 =  BatchNormalization()(dense_fps)#(dense_seq_2)#(conv_seq)\n",
    "\n",
    "\n",
    "#MERGE BOTH BRANCHES\n",
    "main_merged = concatenate([dropout_2, dropout_3],axis=1)#([dense_seq_2, dense_fps], axis=1)\n",
    "\n",
    "main_dense = Dense(2, activation='softmax')(main_merged)\n",
    "\n",
    "#build and compile model\n",
    "model = Model(inputs=[input_seq, input_fps], outputs=[main_dense])\n",
    "model.compile(loss='categorical_crossentropy', optimizer = adamm, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to train \n",
    "sample_size = 10000\n",
    "train_perc = 0.8\n",
    "val_perc = 1 - train_perc\n",
    "np.random.seed(8)\n",
    "training_indices = splitting_list[0]\n",
    "training_size = int(sample_size*train_perc)\n",
    "training_indices_subset = training_indices[:training_size]\n",
    "training_indices_subset.sort()\n",
    "validation_size = int(sample_size*val_perc)\n",
    "val_indices_subset = training_indices[training_size:training_size+validation_size]\n",
    "val_indices_subset.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 28.9084 - accuracy: 0.6049 - val_loss: 6.4351 - val_accuracy: 0.4292\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 25.2266 - accuracy: 0.5767 - val_loss: 5.6964 - val_accuracy: 0.7229\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 13.7507 - accuracy: 0.6110 - val_loss: 3.4128 - val_accuracy: 0.6008\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 9.1871 - accuracy: 0.6453 - val_loss: 3.5009 - val_accuracy: 0.6668\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 5.6179 - accuracy: 0.6501 - val_loss: 12.5188 - val_accuracy: 0.7679\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 3.0224 - accuracy: 0.6660 - val_loss: 1.8658 - val_accuracy: 0.5758- loss: 3.8092 - accura - ETA: 2s - loss: 3.5594 - accura\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 1.2808 - accuracy: 0.6854 - val_loss: 0.9208 - val_accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.9095 - accuracy: 0.6976 - val_loss: 0.8076 - val_accuracy: 0.7114\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.8545 - accuracy: 0.6967 - val_loss: 1.0217 - val_accuracy: 0.6703\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.8105 - accuracy: 0.6861 - val_loss: 0.8349 - val_accuracy: 0.7214 accuracy: 0. - ETA: 0s - loss: 0.8126 - accuracy\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.6954 - accuracy: 0.7036 - val_loss: 0.9785 - val_accuracy: 0.7679\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7297 - accuracy: 0.7005 - val_loss: 0.8080 - val_accuracy: 0.7364: 0.6653 - accuracy:  - ETA: 1s - loss: 0.658 - ETA: 0s - loss: 0.7235 - accuracy\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.6544 - accuracy: 0.7165 - val_loss: 0.7858 - val_accuracy: 0.7244\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6915 - accuracy: 0.7000 - val_loss: 0.7303 - val_accuracy: 0.7574y: \n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7003 - accuracy: 0.7088 - val_loss: 0.7690 - val_accuracy: 0.70640.6938 - accuracy: \n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7144 - accuracy: 0.6991 - val_loss: 0.8209 - val_accuracy: 0.7729ss: - ETA: 0s - loss: 0.7068 - accura - ETA: 0s - loss: 0.7186 - accuracy\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 0.6873 - accuracy: 0.7169 - val_loss: 0.8801 - val_accuracy: 0.6083\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7569 - accuracy: 0.6884 - val_loss: 0.8998 - val_accuracy: 0.6283\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7583 - accuracy: 0.6929 - val_loss: 0.8195 - val_accuracy: 0.6978s - ETA: 1s - ETA: 0s - loss: 0.7322 - accura\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7118 - accuracy: 0.7013 - val_loss: 2.4513 - val_accuracy: 0.7679\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7571 - accuracy: 0.7041 - val_loss: 0.9427 - val_accuracy: 0.7679 2s - loss: 0.7886  - ETA: 1s - loss: 0.7971 - ac - ETA: 1s - loss: 0.7992 - accuracy:  - ETA: 1s - loss: 0\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7047 - accuracy: 0.7125 - val_loss: 0.7675 - val_accuracy: 0.7149s - los\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6870 - accuracy: 0.7066 - val_loss: 0.7656 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.7553 - accuracy: 0.6960 - val_loss: 1.0610 - val_accuracy: 0.7679\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7346 - accuracy: 0.7054 - val_loss: 0.7259 - val_accuracy: 0.7344- ETA: 1s -\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.7013 - accuracy: 0.7066 - val_loss: 0.7169 - val_accuracy: 0.7324\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7296 - accuracy: 0.7046 - val_loss: 0.7221 - val_accuracy: 0.7274\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6896 - accuracy: 0.7067 - val_loss: 0.8321 - val_accuracy: 0.6508\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.6810 - accuracy: 0.7114 - val_loss: 0.7621 - val_accuracy: 0.7689\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7352 - accuracy: 0.7006 - val_loss: 0.7361 - val_accuracy: 0.7344\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7429 - accuracy: 0.7048 - val_loss: 0.8134 - val_accuracy: 0.6688: 0.6339 - accu - ETA: 2s - loss: 0.645 - ETA: 1s - loss: 0.6520 - accuracy: 0.70 - ETA: 1s - l\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7334 - accuracy: 0.7021 - val_loss: 0.8599 - val_accuracy: 0.6823\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7320 - accuracy: 0.7090 - val_loss: 0.8971 - val_accuracy: 0.7679\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6325 - accuracy: 0.7305 - val_loss: 0.7484 - val_accuracy: 0.6868\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6061 - accuracy: 0.7260 - val_loss: 0.8744 - val_accuracy: 0.7679\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7170 - accuracy: 0.7035 - val_loss: 0.7484 - val_accuracy: 0.7374\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: 0.9909 - accuracy: 0.6571 - val_loss: 0.6257 - val_accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.8479 - accuracy: 0.6697 - val_loss: 0.6708 - val_accuracy: 0.7634\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7911 - accuracy: 0.6770 - val_loss: 0.8016 - val_accuracy: 0.6958\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.9027 - accuracy: 0.6693 - val_loss: 1.7926 - val_accuracy: 0.76798728 - \n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7514 - accuracy: 0.6927 - val_loss: 0.8293 - val_accuracy: 0.65780.7152 - accuracy:  - ETA: 0s - loss: 0.7322 - accuracy: \n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7346 - accuracy: 0.6930 - val_loss: 0.8414 - val_accuracy: 0.7679\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7211 - accuracy: 0.7034 - val_loss: 1.1733 - val_accuracy: 0.4702\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6441 - accuracy: 0.7081 - val_loss: 0.6998 - val_accuracy: 0.75590.6343 - ac\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7074 - accuracy: 0.7045 - val_loss: 0.7243 - val_accuracy: 0.7504\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6619 - accuracy: 0.7110 - val_loss: 0.7223 - val_accuracy: 0.7344\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6345 - accuracy: 0.7097 - val_loss: 0.9329 - val_accuracy: 0.7679\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7701 - accuracy: 0.6939 - val_loss: 0.7655 - val_accuracy: 0.71090\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7274 - accuracy: 0.6999 - val_loss: 0.7521 - val_accuracy: 0.7374s\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6775 - accuracy: 0.7124 - val_loss: 0.7270 - val_accuracy: 0.7399\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6862 - accuracy: 0.7042 - val_loss: 0.7307 - val_accuracy: 0.7639\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6961 - accuracy: 0.7153 - val_loss: 1.4900 - val_accuracy: 0.2836 accuracy: 0.71 - E - ETA: 0s - loss: 0.7064 - ac\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 5s 84ms/step - loss: 0.7753 - accuracy: 0.6841 - val_loss: 1.1361 - val_accuracy: 0.7679\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7003 - accuracy: 0.7091 - val_loss: 0.9501 - val_accuracy: 0.7679- loss: 0.7056 \n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6988 - accuracy: 0.7101 - val_loss: 0.7505 - val_accuracy: 0.7689l\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.7631 - accuracy: 0.6921 - val_loss: 1.0843 - val_accuracy: 0.5033\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7038 - accuracy: 0.6936 - val_loss: 0.7907 - val_accuracy: 0.7169\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6877 - accuracy: 0.7258 - val_loss: 0.8852 - val_accuracy: 0.7689- loss: 0.6720 -  - ETA: 1s - loss: 0.6690 - accuracy - ETA: 1s - los\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7753 - accuracy: 0.6985 - val_loss: 1.0249 - val_accuracy: 0.7689\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: 0.7436 - accuracy: 0.7003 - val_loss: 0.8172 - val_accuracy: 0.7139- l - ETA\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7472 - accuracy: 0.6941 - val_loss: 0.8881 - val_accuracy: 0.6718s - loss: 0.6950 \n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7500 - accuracy: 0.6999 - val_loss: 0.9312 - val_accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.8117 - accuracy: 0.6909 - val_loss: 0.8778 - val_accuracy: 0.6933\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7090 - accuracy: 0.6975 - val_loss: 0.8648 - val_accuracy: 0.6893\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7459 - accuracy: 0.7096 - val_loss: 1.6550 - val_accuracy: 0.76790.7003 - accuracy: 0.71 - ETA: 0s - loss: 0.6966 - accuracy: 0.\n",
      "Epoch 30/100\n",
      " 4/63 [>.............................] - ETA: 5s - loss: 0.8151 - accuracy: 0.6797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.108876). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 6s 87ms/step - loss: 0.7097 - accuracy: 0.7081 - val_loss: 0.9898 - val_accuracy: 0.76797089 - ac\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.7324 - accuracy: 0.6974 - val_loss: 0.7949 - val_accuracy: 0.7069- loss: 0.6037 \n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7293 - accuracy: 0.6979 - val_loss: 0.7880 - val_accuracy: 0.7179\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7505 - accuracy: 0.6977 - val_loss: 0.7184 - val_accuracy: 0.7284\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6673 - accuracy: 0.7166 - val_loss: 0.7627 - val_accuracy: 0.7144\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6738 - accuracy: 0.7110 - val_loss: 0.8560 - val_accuracy: 0.6738\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6652 - accuracy: 0.7085 - val_loss: 0.7905 - val_accuracy: 0.7164\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6742 - accuracy: 0.7110 - val_loss: 0.8071 - val_accuracy: 0.7689\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6776 - accuracy: 0.7122 - val_loss: 0.9138 - val_accuracy: 0.7689\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6735 - accuracy: 0.7059 - val_loss: 1.2193 - val_accuracy: 0.7679A: 1s - loss: 0.6 - ETA: 0s - loss: 0.6281 - ac\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 6s 95ms/step - loss: 0.8382 - accuracy: 0.6691 - val_loss: 1.0011 - val_accuracy: 0.7679s - loss: 0.8488 - accuracy: 0. - ETA: 1s - loss: 0.8446 - accuracy - ETA: 1s - loss:\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.6700 - accuracy: 0.7156 - val_loss: 0.7646 - val_accuracy: 0.7329\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7164 - accuracy: 0.7023 - val_loss: 0.7563 - val_accuracy: 0.7329\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7479 - accuracy: 0.6990 - val_loss: 1.1461 - val_accuracy: 0.4862 \n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7011 - accuracy: 0.6988 - val_loss: 0.8677 - val_accuracy: 0.6693\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7448 - accuracy: 0.7049 - val_loss: 0.7935 - val_accuracy: 0.7074\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6908 - accuracy: 0.6984 - val_loss: 0.8247 - val_accuracy: 0.7069\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6287 - accuracy: 0.7182 - val_loss: 0.9156 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.8118 - accuracy: 0.6880 - val_loss: 1.9441 - val_accuracy: 0.7679 1s -\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7841 - accuracy: 0.7059 - val_loss: 0.7641 - val_accuracy: 0.7324\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6964 - accuracy: 0.6989 - val_loss: 0.7601 - val_accuracy: 0.7339loss: 0.6344 - accuracy:  - ETA: 1s - loss: 0.6295 - accuracy: 0.70 - ETA: 1s - los\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6593 - accuracy: 0.7129 - val_loss: 0.9760 - val_accuracy: 0.7679-\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7403 - accuracy: 0.7044 - val_loss: 0.7646 - val_accuracy: 0.76146943 - ac\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7874 - accuracy: 0.6791 - val_loss: 1.8022 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.8031 - accuracy: 0.6964 - val_loss: 0.7879 - val_accuracy: 0.7669: 0.7456  - ETA\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7496 - accuracy: 0.6957 - val_loss: 0.8040 - val_accuracy: 0.7039: 0.7384 -  - ETA: 0s - loss: 0.7311 - accuracy:  - ETA: 0s - loss: 0.7228 \n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6141 - accuracy: 0.7194 - val_loss: 0.8026 - val_accuracy: 0.6718\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6628 - accuracy: 0.7132 - val_loss: 0.7663 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.7464 - accuracy: 0.6990 - val_loss: 0.7565 - val_accuracy: 0.7314\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.8065 - accuracy: 0.6909 - val_loss: 0.8700 - val_accuracy: 0.6888\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6794 - accuracy: 0.7105 - val_loss: 0.7403 - val_accuracy: 0.7304\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 6s 87ms/step - loss: 0.6279 - accuracy: 0.7245 - val_loss: 0.7448 - val_accuracy: 0.7329\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 6s 93ms/step - loss: 0.6743 - accuracy: 0.7110 - val_loss: 0.7446 - val_accuracy: 0.7129\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6965 - accuracy: 0.7049 - val_loss: 0.8832 - val_accuracy: 0.6733\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6843 - accuracy: 0.7069 - val_loss: 0.8015 - val_accuracy: 0.7124\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6720 - accuracy: 0.7140 - val_loss: 0.7865 - val_accuracy: 0.7194\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7344 - accuracy: 0.6980 - val_loss: 0.9426 - val_accuracy: 0.6698\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6586 - accuracy: 0.7164 - val_loss: 1.5720 - val_accuracy: 0.3487\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7540 - accuracy: 0.6852 - val_loss: 0.8054 - val_accuracy: 0.7249- loss: 0.7157 - accuracy: 0.69 - ETA: 0s - loss: 0.7121 - \n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 6s 87ms/step - loss: 0.6726 - accuracy: 0.7014 - val_loss: 0.7735 - val_accuracy: 0.7294\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6724 - accuracy: 0.7032 - val_loss: 0.7903 - val_accuracy: 0.7224- loss: 0.6\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7058 - accuracy: 0.7161 - val_loss: 0.9530 - val_accuracy: 0.7679\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.6938 - accuracy: 0.7038 - val_loss: 0.7854 - val_accuracy: 0.7294\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7954 - accuracy: 0.6950 - val_loss: 1.4801 - val_accuracy: 0.4197s - loss: 0.8141 - accuracy: 0.70 - ETA: \n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6858 - accuracy: 0.7048 - val_loss: 0.7093 - val_accuracy: 0.7609\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.8512 - accuracy: 0.6845 - val_loss: 0.8361 - val_accuracy: 0.7084- loss: 0.832\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 6s 92ms/step - loss: 0.6665 - accuracy: 0.7066 - val_loss: 0.7391 - val_accuracy: 0.7734\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.6858 - accuracy: 0.7042 - val_loss: 0.7415 - val_accuracy: 0.7334: 0.6916 - accuracy:  - - ETA: 0s - loss: 0.6855 - accuracy: \n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7067 - accuracy: 0.7185 - val_loss: 0.9966 - val_accuracy: 0.7679\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7839 - accuracy: 0.6977 - val_loss: 0.7853 - val_accuracy: 0.7319\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6960 - accuracy: 0.7009 - val_loss: 0.8457 - val_accuracy: 0.6848\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6371 - accuracy: 0.7197 - val_loss: 0.7422 - val_accuracy: 0.7164: 0.6425 - accuracy: 0.72 - ETA: 2s - loss: 0.643 - ETA: 1s -\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7914 - accuracy: 0.7040 - val_loss: 0.9637 - val_accuracy: 0.7689\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 5s 84ms/step - loss: 0.6814 - accuracy: 0.7155 - val_loss: 0.9022 - val_accuracy: 0.7689\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 6s 91ms/step - loss: 0.6839 - accuracy: 0.7124 - val_loss: 0.7678 - val_accuracy: 0.7209\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7051 - accuracy: 0.7016 - val_loss: 0.7491 - val_accuracy: 0.7379\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7280 - accuracy: 0.7038 - val_loss: 0.8422 - val_accuracy: 0.7144\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6659 - accuracy: 0.7176 - val_loss: 1.4249 - val_accuracy: 0.4232\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7373 - accuracy: 0.6860 - val_loss: 0.8055 - val_accuracy: 0.7159\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6996 - accuracy: 0.6991 - val_loss: 0.7798 - val_accuracy: 0.7259\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7223 - accuracy: 0.7044 - val_loss: 0.8046 - val_accuracy: 0.7134\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6551 - accuracy: 0.7209 - val_loss: 1.0132 - val_accuracy: 0.53580.6322 - accuracy:  - ETA: 3s - loss: 0.6110 - accuracy: 0.73 - ETA:  - E\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7081 - accuracy: 0.7046 - val_loss: 0.8077 - val_accuracy: 0.6958\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6505 - accuracy: 0.7251 - val_loss: 0.7527 - val_accuracy: 0.71840.619 - ETA: \n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6118 - accuracy: 0.7287 - val_loss: 0.7559 - val_accuracy: 0.6958y: 0.72 - ETA: 1s - loss: 0.6058 - accuracy:  - ETA: 1s - los\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.7162 - accuracy: 0.7056 - val_loss: 0.8405 - val_accuracy: 0.6843\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7151 - accuracy: 0.6939 - val_loss: 0.8993 - val_accuracy: 0.6653s - loss: 0.6645 - ac\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 6s 95ms/step - loss: 1.0747 - accuracy: 0.6396 - val_loss: 0.7336 - val_accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 0.9311 - accuracy: 0.6570 - val_loss: 0.7780 - val_accuracy: 0.7679\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7428 - accuracy: 0.6846 - val_loss: 0.7635 - val_accuracy: 0.5733 accuracy: 0.70 - ETA: 1s - loss: 0.6819 - accuracy:  - ETA: 0s - loss: 0.6775 \n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7991 - accuracy: 0.6830 - val_loss: 0.6956 - val_accuracy: 0.7634: 0.8066 - accuracy\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 0.6831 - accuracy: 0.7053 - val_loss: 0.7284 - val_accuracy: 0.7359\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7270 - accuracy: 0.6864 - val_loss: 1.0618 - val_accuracy: 0.4217\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7410 - accuracy: 0.6827 - val_loss: 0.7546 - val_accuracy: 0.7734\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.7563 - accuracy: 0.6979 - val_loss: 0.8782 - val_accuracy: 0.7679\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.7556 - accuracy: 0.6959 - val_loss: 1.2727 - val_accuracy: 0.4432\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7352 - accuracy: 0.6919 - val_loss: 0.7521 - val_accuracy: 0.7419- loss: 0.6776 - accuracy: 0.70 - ETA: 2s - ETA: 0s - loss: 0.6827 - accuracy: 0.70 - ETA: 0s - loss: 0.6794 \n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 6s 87ms/step - loss: 0.7125 - accuracy: 0.7076 - val_loss: 0.7733 - val_accuracy: 0.7399\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 6s 89ms/step - loss: 0.6566 - accuracy: 0.7051 - val_loss: 0.7542 - val_accuracy: 0.7399\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.6316 - accuracy: 0.7279 - val_loss: 0.8815 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.6981 - accuracy: 0.7069 - val_loss: 0.7241 - val_accuracy: 0.7364\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.6725 - accuracy: 0.7140 - val_loss: 0.7230 - val_accuracy: 0.7319\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 6s 90ms/step - loss: 0.6811 - accuracy: 0.7149 - val_loss: 0.7960 - val_accuracy: 0.7049: 0.6633 - accuracy\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6712 - accuracy: 0.7184 - val_loss: 1.2295 - val_accuracy: 0.4692 2s - loss: 0.5877 - ac - ETA: 2s - loss: 0.5905 - accuracy: 0.74 - ETA: 2s - loss: 0.599 - ETA: 1s\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.7548 - accuracy: 0.6977 - val_loss: 0.7614 - val_accuracy: 0.7099\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6265 - accuracy: 0.7255 - val_loss: 0.7418 - val_accuracy: 0.7334\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.7224 - accuracy: 0.7101 - val_loss: 0.7585 - val_accuracy: 0.7339 accuracy\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.8640 - accuracy: 0.6653 - val_loss: 1.8290 - val_accuracy: 0.7679: 0.8310 - accuracy: 0.67 - ETA: 0s - loss: 0.8480 - ac\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.6863 - accuracy: 0.7275 - val_loss: 0.8470 - val_accuracy: 0.7689\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7494 - accuracy: 0.6999 - val_loss: 0.7651 - val_accuracy: 0.7274s - loss: 0.6730 - accuracy: 0.72 - E - ETA: 0s - loss: 0.7452 - accuracy: 0.\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6478 - accuracy: 0.7154 - val_loss: 0.7677 - val_accuracy: 0.7709 3s - l - ETA: \n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.7008 - accuracy: 0.7025 - val_loss: 0.8356 - val_accuracy: 0.6908s - loss: 0.6528 - accura - E\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 0.6478 - accuracy: 0.7134 - val_loss: 0.7268 - val_accuracy: 0.7309\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 6s 87ms/step - loss: 0.6839 - accuracy: 0.7179 - val_loss: 0.7192 - val_accuracy: 0.7379\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 22s 352ms/step - loss: 2.7408 - accuracy: 0.6460 - val_loss: 0.6164 - val_accuracy: 0.7379\n",
      "Epoch 2/100\n",
      " 2/63 [..............................] - ETA: 8s - loss: 0.8792 - accuracy: 0.6719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.121136). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s 302ms/step - loss: 1.0368 - accuracy: 0.6323 - val_loss: 0.6528 - val_accuracy: 0.7254\n",
      "Epoch 3/100\n",
      " 3/63 [>.............................] - ETA: 6s - loss: 0.7803 - accuracy: 0.6510"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.129906). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 20s 323ms/step - loss: 0.7942 - accuracy: 0.6629 - val_loss: 0.6307 - val_accuracy: 0.7499\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 19s 309ms/step - loss: 0.9075 - accuracy: 0.6559 - val_loss: 0.6413 - val_accuracy: 0.7509\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 19s 304ms/step - loss: 0.8160 - accuracy: 0.6841 - val_loss: 0.6529 - val_accuracy: 0.7644c - ETA: 3s - los\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.7360 - accuracy: 0.7016 - val_loss: 0.6995 - val_accuracy: 0.7434\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.7048 - accuracy: 0.6996 - val_loss: 0.8024 - val_accuracy: 0.6898\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 0.7394 - accuracy: 0.6826 - val_loss: 0.8734 - val_accuracy: 0.6323\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.6871 - accuracy: 0.7032 - val_loss: 0.9379 - val_accuracy: 0.5363\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 0.7042 - accuracy: 0.6956 - val_loss: 1.3946 - val_accuracy: 0.3907\n",
      "Epoch 11/100\n",
      " 3/63 [>.............................] - ETA: 7s - loss: 0.9059 - accuracy: 0.5703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.171994). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.101121). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 329ms/step - loss: 0.6907 - accuracy: 0.6949 - val_loss: 0.7836 - val_accuracy: 0.7169\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.6817 - accuracy: 0.7138 - val_loss: 1.0084 - val_accuracy: 0.5388\n",
      "Epoch 13/100\n",
      " 2/63 [..............................] - ETA: 9s - loss: 0.7164 - accuracy: 0.6133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.124773). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.104945). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 329ms/step - loss: 0.7944 - accuracy: 0.6877 - val_loss: 1.7587 - val_accuracy: 0.7679\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.7735 - accuracy: 0.6951 - val_loss: 1.2312 - val_accuracy: 0.7679\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.7062 - accuracy: 0.7007 - val_loss: 0.8740 - val_accuracy: 0.6843 loss: 0.6606 - ac - ETA: 6s - loss: 0.6542 - accuracy: 0.72 - E\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 21s 327ms/step - loss: 0.6470 - accuracy: 0.7218 - val_loss: 0.7688 - val_accuracy: 0.7164\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.6185 - accuracy: 0.7195 - val_loss: 1.0895 - val_accuracy: 0.4627\n",
      "Epoch 18/100\n",
      " 2/63 [..............................] - ETA: 9s - loss: 0.8090 - accuracy: 0.5547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.169949). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.141066). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/63 [>.............................] - ETA: 9s - loss: 0.6426 - accuracy: 0.6797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.112183). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 327ms/step - loss: 0.6869 - accuracy: 0.7101 - val_loss: 0.7943 - val_accuracy: 0.7314A: 10s - loss: 0.592\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.7574 - accuracy: 0.6964 - val_loss: 0.8442 - val_accuracy: 0.7694\n",
      "Epoch 20/100\n",
      " 2/63 [..............................] - ETA: 7s - loss: 1.1732 - accuracy: 0.5664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.140530). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.114388). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 19s 298ms/step - loss: 0.7121 - accuracy: 0.7116 - val_loss: 0.7594 - val_accuracy: 0.7239\n",
      "Epoch 21/100\n",
      " 4/63 [>.............................] - ETA: 7s - loss: 0.5523 - accuracy: 0.7207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.115782). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 338ms/step - loss: 0.6455 - accuracy: 0.7165 - val_loss: 0.7863 - val_accuracy: 0.7694\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.6312 - accuracy: 0.7325 - val_loss: 0.7273 - val_accuracy: 0.7264\n",
      "Epoch 23/100\n",
      " 3/63 [>.............................] - ETA: 9s - loss: 0.5909 - accuracy: 0.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.122362). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 327ms/step - loss: 0.6518 - accuracy: 0.7126 - val_loss: 0.7765 - val_accuracy: 0.7169- loss: 0.6397 - ac\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.6817 - accuracy: 0.7035 - val_loss: 0.7440 - val_accuracy: 0.7579\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.6128 - accuracy: 0.7251 - val_loss: 0.7575 - val_accuracy: 0.7159\n",
      "Epoch 26/100\n",
      "13/63 [=====>........................] - ETA: 20s - loss: 0.7994 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.102669). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 21s 330ms/step - loss: 0.7762 - accuracy: 0.7014 - val_loss: 0.7749 - val_accuracy: 0.7149\n",
      "Epoch 27/100\n",
      "14/63 [=====>........................] - ETA: 18s - loss: 0.6656 - accuracy: 0.6886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.111405). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "15/63 [======>.......................] - ETA: 19s - loss: 0.6814 - accuracy: 0.6865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.125504). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 20s 325ms/step - loss: 0.6770 - accuracy: 0.7100 - val_loss: 2.6244 - val_accuracy: 0.7679\n",
      "Epoch 28/100\n",
      "19/63 [========>.....................] - ETA: 16s - loss: 0.8607 - accuracy: 0.6994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.102090). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 20s 323ms/step - loss: 0.7672 - accuracy: 0.7013 - val_loss: 0.8303 - val_accuracy: 0.7034\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.7396 - accuracy: 0.6979 - val_loss: 0.7800 - val_accuracy: 0.7109\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.6882 - accuracy: 0.7229 - val_loss: 0.9062 - val_accuracy: 0.5598\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.6702 - accuracy: 0.7091 - val_loss: 0.7327 - val_accuracy: 0.7304\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.5956 - accuracy: 0.7340 - val_loss: 0.8865 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 21s 327ms/step - loss: 0.6971 - accuracy: 0.7091 - val_loss: 0.8333 - val_accuracy: 0.7039 accuracy: \n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 20s 322ms/step - loss: 0.7544 - accuracy: 0.6927 - val_loss: 0.8016 - val_accuracy: 0.7294\n",
      "Epoch 35/100\n",
      " 2/63 [..............................] - ETA: 9s - loss: 0.6311 - accuracy: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.135503). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 20s 318ms/step - loss: 0.6496 - accuracy: 0.7235 - val_loss: 0.7825 - val_accuracy: 0.7254\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.6616 - accuracy: 0.7188 - val_loss: 1.0250 - val_accuracy: 0.7679\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 20s 323ms/step - loss: 0.7175 - accuracy: 0.7078 - val_loss: 0.8168 - val_accuracy: 0.70399 - acc - ETA: 9s - loss: 0.6528 -\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 21s 326ms/step - loss: 0.6597 - accuracy: 0.7151 - val_loss: 0.7972 - val_accuracy: 0.7369\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 21s 327ms/step - loss: 0.7508 - accuracy: 0.6955 - val_loss: 0.8124 - val_accuracy: 0.7214\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 11s 182ms/step - loss: 0.8820 - accuracy: 0.6654 - val_loss: 0.7237 - val_accuracy: 0.2921\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 10s 164ms/step - loss: 0.7799 - accuracy: 0.6879 - val_loss: 0.9325 - val_accuracy: 0.7679\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 0.7785 - accuracy: 0.6892 - val_loss: 0.6352 - val_accuracy: 0.7644\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.6918 - accuracy: 0.6946 - val_loss: 0.6318 - val_accuracy: 0.7674\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.7164 - accuracy: 0.6884 - val_loss: 0.6287 - val_accuracy: 0.7679\n",
      "Epoch 6/100\n",
      " 5/63 [=>............................] - ETA: 3s - loss: 0.6292 - accuracy: 0.7141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.111119). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 11s 168ms/step - loss: 0.6826 - accuracy: 0.6825 - val_loss: 0.6153 - val_accuracy: 0.7679\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.7801 - accuracy: 0.6631 - val_loss: 0.6283 - val_accuracy: 0.7659\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 0.9245 - accuracy: 0.6490 - val_loss: 0.6292 - val_accuracy: 0.7624\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 0.7635 - accuracy: 0.6794 - val_loss: 0.6177 - val_accuracy: 0.7674\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.8253 - accuracy: 0.6841 - val_loss: 0.6319 - val_accuracy: 0.7444\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.7168 - accuracy: 0.6833 - val_loss: 0.6705 - val_accuracy: 0.6218\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.7017 - accuracy: 0.6850 - val_loss: 0.6344 - val_accuracy: 0.7579\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.7961 - accuracy: 0.6945 - val_loss: 0.6219 - val_accuracy: 0.7444\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 0.7845 - accuracy: 0.6856 - val_loss: 0.6588 - val_accuracy: 0.6498\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.7588 - accuracy: 0.6940 - val_loss: 0.6468 - val_accuracy: 0.7019\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 0.7856 - accuracy: 0.6923 - val_loss: 0.8174 - val_accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.7450 - accuracy: 0.6827 - val_loss: 0.6342 - val_accuracy: 0.7304\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.8255 - accuracy: 0.6683 - val_loss: 0.8446 - val_accuracy: 0.7679\n",
      "Epoch 19/100\n",
      " 3/63 [>.............................] - ETA: 6s - loss: 0.6761 - accuracy: 0.7214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.118713). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 11s 167ms/step - loss: 0.7381 - accuracy: 0.6860 - val_loss: 0.6708 - val_accuracy: 0.6298\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.8050 - accuracy: 0.6718 - val_loss: 0.6417 - val_accuracy: 0.7094\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.7784 - accuracy: 0.6670 - val_loss: 0.6766 - val_accuracy: 0.5803\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.8420 - accuracy: 0.6716 - val_loss: 0.6352 - val_accuracy: 0.7109\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 25s 402ms/step - loss: 0.7644 - accuracy: 0.6716 - val_loss: 1.0181 - val_accuracy: 0.7679\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 22s 343ms/step - loss: 0.6897 - accuracy: 0.7011 - val_loss: 0.7833 - val_accuracy: 0.6753\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 23s 372ms/step - loss: 0.6724 - accuracy: 0.7175 - val_loss: 0.7599 - val_accuracy: 0.7194\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 23s 370ms/step - loss: 0.6396 - accuracy: 0.7081 - val_loss: 0.9012 - val_accuracy: 0.7679\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 23s 365ms/step - loss: 0.6732 - accuracy: 0.7075 - val_loss: 0.7886 - val_accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 24s 374ms/step - loss: 0.7684 - accuracy: 0.7048 - val_loss: 0.9206 - val_accuracy: 0.5993\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 22s 357ms/step - loss: 0.7279 - accuracy: 0.6940 - val_loss: 1.0989 - val_accuracy: 0.7679\n",
      "Epoch 8/100\n",
      " 2/63 [..............................] - ETA: 7s - loss: 0.5755 - accuracy: 0.7461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.128430). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 373ms/step - loss: 0.6672 - accuracy: 0.7121 - val_loss: 0.7652 - val_accuracy: 0.7359\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 23s 361ms/step - loss: 0.7251 - accuracy: 0.7049 - val_loss: 1.1200 - val_accuracy: 0.7679\n",
      "Epoch 10/100\n",
      "14/63 [=====>........................] - ETA: 21s - loss: 0.6858 - accuracy: 0.7316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.147251). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.104251). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 370ms/step - loss: 0.6680 - accuracy: 0.7160 - val_loss: 0.7255 - val_accuracy: 0.7634\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 23s 364ms/step - loss: 0.6471 - accuracy: 0.7109 - val_loss: 0.7459 - val_accuracy: 0.7209\n",
      "Epoch 12/100\n",
      " 3/63 [>.............................] - ETA: 9s - loss: 0.5653 - accuracy: 0.7266 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.162646). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.110691). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 368ms/step - loss: 0.6773 - accuracy: 0.7103 - val_loss: 0.7746 - val_accuracy: 0.7454\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 23s 368ms/step - loss: 0.6738 - accuracy: 0.7146 - val_loss: 0.8996 - val_accuracy: 0.6653\n",
      "Epoch 14/100\n",
      " 5/63 [=>............................] - ETA: 6s - loss: 0.6676 - accuracy: 0.7109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.110448). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 370ms/step - loss: 0.6716 - accuracy: 0.7139 - val_loss: 0.7744 - val_accuracy: 0.7199\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 23s 364ms/step - loss: 0.6791 - accuracy: 0.7185 - val_loss: 0.8647 - val_accuracy: 0.6583\n",
      "Epoch 16/100\n",
      " 2/63 [..............................] - ETA: 8s - loss: 0.7646 - accuracy: 0.6484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.120983). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/63 [=>............................] - ETA: 8s - loss: 0.6783 - accuracy: 0.7044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.100044). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/63 [=====>........................] - ETA: 20s - loss: 0.6976 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.104253). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/63 [=======>......................] - ETA: 20s - loss: 0.6764 - accuracy: 0.6893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.103917). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 369ms/step - loss: 0.6673 - accuracy: 0.7079 - val_loss: 0.7425 - val_accuracy: 0.7759\n",
      "Epoch 17/100\n",
      " 3/63 [>.............................] - ETA: 7s - loss: 0.6366 - accuracy: 0.7708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.105766). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 22s 352ms/step - loss: 0.6834 - accuracy: 0.7155 - val_loss: 0.7473 - val_accuracy: 0.7219\n",
      "Epoch 18/100\n",
      " 4/63 [>.............................] - ETA: 7s - loss: 0.5602 - accuracy: 0.7559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.208330). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.107396). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 24s 374ms/step - loss: 0.6717 - accuracy: 0.7189 - val_loss: 0.8798 - val_accuracy: 0.7689\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 22s 357ms/step - loss: 0.7315 - accuracy: 0.7050 - val_loss: 0.8076 - val_accuracy: 0.7184\n",
      "Epoch 20/100\n",
      " 3/63 [>.............................] - ETA: 6s - loss: 0.5859 - accuracy: 0.7161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.119726). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 361ms/step - loss: 0.6200 - accuracy: 0.7309 - val_loss: 1.1967 - val_accuracy: 0.4192\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 23s 370ms/step - loss: 0.7327 - accuracy: 0.6949 - val_loss: 1.1336 - val_accuracy: 0.5318\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 23s 361ms/step - loss: 0.6481 - accuracy: 0.7224 - val_loss: 0.7275 - val_accuracy: 0.7214\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 23s 370ms/step - loss: 0.6664 - accuracy: 0.7194 - val_loss: 0.8522 - val_accuracy: 0.6848\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 23s 363ms/step - loss: 0.7644 - accuracy: 0.7063 - val_loss: 1.3251 - val_accuracy: 0.4312\n",
      "Epoch 25/100\n",
      " 4/63 [>.............................] - ETA: 8s - loss: 0.8842 - accuracy: 0.6211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.131076). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.103495). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 24s 377ms/step - loss: 0.7370 - accuracy: 0.6965 - val_loss: 0.7849 - val_accuracy: 0.7149\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 23s 373ms/step - loss: 0.7166 - accuracy: 0.7024 - val_loss: 0.8690 - val_accuracy: 0.6878\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 22s 349ms/step - loss: 0.6887 - accuracy: 0.7100 - val_loss: 2.5296 - val_accuracy: 0.7679\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 24s 374ms/step - loss: 0.7609 - accuracy: 0.6967 - val_loss: 0.7981 - val_accuracy: 0.7744\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 23s 357ms/step - loss: 0.6418 - accuracy: 0.7151 - val_loss: 0.7531 - val_accuracy: 0.7349\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 24s 375ms/step - loss: 0.6374 - accuracy: 0.7161 - val_loss: 0.7594 - val_accuracy: 0.7339\n",
      "Epoch 31/100\n",
      " 2/63 [..............................] - ETA: 8s - loss: 0.5956 - accuracy: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.107893). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.116982). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 367ms/step - loss: 0.7501 - accuracy: 0.6777 - val_loss: 0.8170 - val_accuracy: 0.7744\n",
      "Epoch 32/100\n",
      " 4/63 [>.............................] - ETA: 6s - loss: 0.5683 - accuracy: 0.7656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.108284). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 372ms/step - loss: 0.6995 - accuracy: 0.7191 - val_loss: 0.8184 - val_accuracy: 0.7749\n",
      "Epoch 33/100\n",
      " 3/63 [>.............................] - ETA: 6s - loss: 0.6398 - accuracy: 0.7214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.110324). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/63 [==>...........................] - ETA: 15s - loss: 0.6849 - accuracy: 0.7402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.100138). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 9/63 [===>..........................] - ETA: 17s - loss: 0.7040 - accuracy: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.105180). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 372ms/step - loss: 0.7145 - accuracy: 0.7003 - val_loss: 0.8340 - val_accuracy: 0.7104\n",
      "Epoch 34/100\n",
      " 4/63 [>.............................] - ETA: 7s - loss: 0.7741 - accuracy: 0.6172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.101445). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/63 [==>...........................] - ETA: 10s - loss: 0.7162 - accuracy: 0.6786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.119218). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 362ms/step - loss: 0.7717 - accuracy: 0.6935 - val_loss: 0.7429 - val_accuracy: 0.7589\n",
      "Epoch 35/100\n",
      " 4/63 [>.............................] - ETA: 8s - loss: 0.6437 - accuracy: 0.7168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.109058). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 367ms/step - loss: 0.6963 - accuracy: 0.7197 - val_loss: 0.7757 - val_accuracy: 0.7319\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 23s 367ms/step - loss: 0.7090 - accuracy: 0.7070 - val_loss: 0.7851 - val_accuracy: 0.7299\n"
     ]
    }
   ],
   "source": [
    "for type_padding_prot in list_paddings:\n",
    "    #Defining generators\n",
    "    train_generator = batch_generator_DL(batch_size, f, group, table, training_indices_subset, \n",
    "                                     max_len_prot, type_padding_prot=type_padding_prot)\n",
    "    val_generator = batch_generator_DL(batch_size, f, group, table, val_indices_subset, \n",
    "                                     max_len_prot, type_padding_prot=type_padding_prot)\n",
    "    name_padding_prot = type_padding_prot.split(\"_\")[0]\n",
    "    if not os.path.exists(\"\".join((absPath, \"data/padding_tuning/\", name_padding_prot))):\n",
    "        os.makedirs(\"\".join((absPath, \"data/padding_tuning/\", name_padding_prot)))\n",
    "\n",
    "    #if there are already files in the folder, it removes them\n",
    "    r = glob(\"\".join((absPath, \"data/padding_tuning/\", name_padding_prot, \"/*.hdf5\")))\n",
    "    for i in r:\n",
    "        os.remove(i)\n",
    "   \n",
    "    terminan = TerminateOnNaN()\n",
    "    checkpoint_path = \"\".join((absPath, \"data/padding_tuning/\", name_padding_prot,\n",
    "                           \"/weights-improvement-{epoch:03d}-{val_accuracy:.4f}.hdf5\"))\n",
    "    mcheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, \n",
    "                                          save_best_only=True, save_weights_only=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, \n",
    "                                       restore_best_weights=True)\n",
    "    callbacks_list = [terminan, mcheckpoint, early_stopping]\n",
    "\n",
    "    his = model.fit_generator(generator=train_generator, validation_data=val_generator, \n",
    "                        steps_per_epoch=ceil(len(training_indices_subset)/batch_size),\n",
    "                        validation_steps=ceil(len(val_indices_subset)/batch_size), \n",
    "                        epochs=n_epochs, callbacks=callbacks_list)\n",
    "\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type padding protein post_padding\n",
      "Type padding protein pre_padding\n",
      "Type padding protein mid_padding\n",
      "Type padding protein ext_padding\n",
      "Type padding protein strf_padding\n",
      "Type padding protein rnd_padding\n",
      "Type padding protein zoom_padding\n"
     ]
    }
   ],
   "source": [
    "# Getting y_true\n",
    "splitting_list[2].sort()\n",
    "y_true = f[group][table][splitting_list[2]][\"label\"]\n",
    "\n",
    "# Looping to get all the results\n",
    "df_total = pd.DataFrame(columns=[\"f1\", \"pad_prot\", \"pad_comp\"])\n",
    "idx = 0\n",
    "for type_padding_prot in list_paddings:\n",
    "    print(\"Type padding protein\", type_padding_prot)\n",
    "    dict_prot = {}\n",
    "    #Defining generators\n",
    "    test_generator = batch_generator_DL(batch_size, f, group, table, splitting_list[2], \n",
    "                                     max_len_prot, type_padding_prot=type_padding_prot)\n",
    "    name_padding_prot = type_padding_prot.split(\"_\")[0]\n",
    "    model_path = \"\".join((absPath, \"data/padding_tuning/\",  name_padding_prot, \"/\"))\n",
    "    r = glob(\"\".join((model_path, \"*.hdf5\")))\n",
    "    model = load_model(r[0])\n",
    "    predprob = model.predict_generator(test_generator, steps=round(len(splitting_list[2])/batch_size))\n",
    "    y_test = predprob.argmax(axis=-1)   \n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_test)\n",
    "\n",
    "    df_total.loc[idx,\"f1\"] = round(f1,3)\n",
    "    df_total.loc[idx, \"pad_prot\"] = name_padding_prot\n",
    "        \n",
    "    idx = idx+1\n",
    "                             \n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"f1\"] = pd.to_numeric(df_total[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8780033071126)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plotting result     \n",
    "p = (ggplot(df_total, aes(x=\"pad_prot\", y=\"f1\", fill=\"factor(pad_prot)\")) \n",
    " + geom_bar(position=\"dodge\", stat=\"identity\")\n",
    "+ xlab(\"protein padding type\")\n",
    "#+ scale_fill_discrete(name = \"compound padding type\")\n",
    "+ ylab(\"F1 score\")\n",
    ") \n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angela3/venv/lib/python3.6/site-packages/plotnine/ggplot.py:729: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "  from_inches(height, units), units), PlotnineWarning)\n",
      "/home/angela3/venv/lib/python3.6/site-packages/plotnine/ggplot.py:730: PlotnineWarning: Filename: /home/angela3/imbalance_pcm_benchmark/data/padding_tuning/padding_tuning_result.pdf\n",
      "  warn('Filename: {}'.format(filename), PlotnineWarning)\n"
     ]
    }
   ],
   "source": [
    "ggsave(plot=p, filename=\"\".join((absPath, \"data/padding_tuning/padding_tuning_result.pdf\")), dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
