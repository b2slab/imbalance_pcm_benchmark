{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tables import *\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela3/imbalance_pcm_benchmark/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "from src.imbalance_functions import labelling\n",
    "\n",
    "np.random.seed(8)\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this script to run, the cleared dataset provided by the DeepAffinity repository (https://github.com/Shen-Lab/DeepAffinity/) must be downloaded into a subfolder in this repo called *raw_data*.\n",
    "The cleared dataset from DeepAffinity can be found in https://drive.google.com/open?id=1_msEbSh_YZr0NLSR_DJ_xWE9FlqBlMV9 and the files are explained in the data folder of the DeepAffinity repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the measure method for protein compound pairs (for EC50, IC50, Kd, Ki).\n",
    "measurement_types = [\"EC50\", \"IC50\", \"Kd\", \"Ki\"]\n",
    "list_measurements = []\n",
    "for typee in measurement_types:\n",
    "    measure_pairs_file = \"\".join((absPath, \"raw_data/\", typee, \"_protein_compound_pair.tsv\"))\n",
    "    measure_pairs_df = pd.read_csv(measure_pairs_file, sep='\\t', header=0)\n",
    "    list_measurements.append(measure_pairs_df)\n",
    "    \n",
    "pairs_df = pd.concat(list_measurements)\n",
    "\n",
    "#columns we want to collapse into one\n",
    "val_cols = ['pEC50_[M]', 'pIC50_[M]', 'pKd_[M]', 'pKi_[M]']\n",
    "\n",
    "pairs_df['activity'] = pd.to_numeric(pairs_df[val_cols].bfill(axis=1).iloc[:, 0], errors='coerce')\n",
    "pairs_df.drop(val_cols, axis=1, inplace=True)\n",
    "\n",
    "pairs_df['label'] = pairs_df.apply(labelling, axis=1)\n",
    "\n",
    "print(pairs_df.head())\n",
    "print(pairs_df.info())\n",
    "\n",
    "#Loading SMILES data\n",
    "smiles_filename = \"\".join((absPath, \"raw_data/dcid_smi.tsv\"))\n",
    "smiles_df = pd.read_csv(smiles_filename, sep='\\t', header=0)\n",
    "\n",
    "print(smiles_df.head())\n",
    "print(smiles_df.info())\n",
    "\n",
    "#Loading proteins data\n",
    "prot_filename = \"\".join((absPath, \"raw_data/dpid_seq.tsv\"))\n",
    "prots_df = pd.read_csv(prot_filename, sep='\\t', header=0)\n",
    "\n",
    "print(prots_df.head())\n",
    "print(prots_df.info())\n",
    "\n",
    "#Loading Pfam data (just in case)\n",
    "pfam_filename = \"\".join((absPath, \"raw_data/dpid_dom.tsv\"))\n",
    "pfam_df = pd.read_csv(pfam_filename, sep='\\t', header=0)\n",
    "\n",
    "print(pfam_df.head())\n",
    "print(pfam_df.info())\n",
    "\n",
    "#Creating dictionary of compounds\n",
    "dict_smiles = creating_smiles_dictionary(smiles_df[\"Canonical SMILE\"].values)\n",
    "\n",
    "#Joining dataframes\n",
    "concat_pairs_smiles = pd.merge(pairs_df, smiles_df, on=\"DeepAffinity Compound ID\")\n",
    "concat_pairs_prots = pd.merge(concat_pairs_smiles, prots_df, on=\"DeepAffinity Protein ID\")\n",
    "#Pfam signatures are too heavy to save\n",
    "#concat_final = pd.merge(concat_pairs_prots, pfam_df, on=\"DeepAffinity Protein ID\")\n",
    "\n",
    "#Trying to join proteins to families\n",
    "prot_families = ['NR', 'GPCR', 'CY', 'PK', 'TR', 'IC', 'OE', 'PR']\n",
    "file_fams = \"\".join((absPath, \"raw_data/Uniprot/\"))\n",
    "fams_list = []\n",
    "for prot_fam in prot_families:\n",
    "    file_fam = \"\".join((file_fams, prot_fam, \".txt\"))\n",
    "    df_fam = pd.read_csv(file_fam, delimiter='\\t', usecols=[3])\n",
    "    df_fam['family'] = prot_fam\n",
    "    fams_list.append(df_fam)\n",
    "\n",
    "families = pd.concat(fams_list, ignore_index=True)\n",
    "families.columns = ['Uniprot ID', 'family']\n",
    "print(families.info())\n",
    "#Joining dataframes\n",
    "# unimos ambos \n",
    "activity_df_fams = pd.merge(concat_pairs_prots, families, on=['Uniprot ID'], how='left')\n",
    "print(activity_df_fams.info())    \n",
    "# Hay 242.840 prots que no tienen asignadas familias\n",
    "activity_df_fams['family'].fillna(\"Non assigned\", inplace=True)\n",
    "\n",
    "#Saving final dataset to a csv\n",
    "output_filename = \"\".join((absPath, \"data/smiles_prots_activity.csv\"))\n",
    "activity_df_fams.to_csv(output_filename, sep=\"\\t\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
