{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "from sklearn import metrics \n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tables import *\n",
    "\n",
    "from keras import backend as K \n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.backend import manual_variable_initialization \n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, concatenate, Flatten, Conv1D, BatchNormalization, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TerminateOnNaN\n",
    "#import keras\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela3/imbalance_pcm_benchmark/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "\n",
    "from src.model_functions import *\n",
    "from src.Target import Target\n",
    "from src.postproc_auxiliar_functions import *\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0' \n",
    "np.random.seed(8)\n",
    "random.seed(8)\n",
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/angela3/imbalance_pcm_benchmark/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 10\n",
    "batch_size = 128\n",
    "epochss = 100\n",
    "type_padding_prot = \"pre_padding\"\n",
    "protein_type = \"GPCRs\" #\"kinases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening HDF5 with data\n",
    "file_h5 = \"\".join((absPath, \"data/\", protein_type,\"/no_resampling/compounds_activity.h5\"))\n",
    "f = h5py.File(file_h5, 'r')\n",
    "group = '/activity'\n",
    "table = \"prot_comp\"\n",
    "\n",
    "#Loading maximum lengths of proteins and compounds\n",
    "with open(\"\".join((absPath, 'data/prot_max_len.pickle')), \"rb\") as input_file:\n",
    "    max_len_prot = pickle.load(input_file)\n",
    "#Defining protein dictionary    \n",
    "instarget = Target(\"AAA\")\n",
    "prot_dict = instarget.predefining_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "decay_rate = learning_rate/epochss\n",
    "adamm = Adam(lr=learning_rate, beta_1=0.1, beta_2=0.001, epsilon=1e-08, decay=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1499, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1499, 64)     5056        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1499, 64)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 95936)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 881)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           4796850     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           44100       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            202         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,846,208\n",
      "Trainable params: 4,846,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LEFT BLOCK (to analyse amino acid sequences)\n",
    "input_seq = Input(shape=(max_len_prot, len(prot_dict)), dtype='float32')\n",
    "conv_seq = Conv1D(filters=64, padding='same', strides=1, kernel_size=3, activation='relu')(input_seq)\n",
    "dropout_1 = Dropout(0.4)(conv_seq)\n",
    "flatten_seq = Flatten()(dropout_1)#(dense_seq)\n",
    "dense_seq_2 = Dense(50)(flatten_seq)\n",
    "dropout_2 = Dropout(0.4)(dense_seq_2)\n",
    "\n",
    "#RIGHT BRANCH (to analyse fingerprints)\n",
    "input_fps = Input(shape=(881,), dtype='float32')\n",
    "dense_fps = Dense(50)(input_fps)\n",
    "dropout_3 = Dropout(0.4)(dense_fps)\n",
    "#bn_3 =  BatchNormalization()(dense_fps)#(dense_seq_2)#(conv_seq)\n",
    "\n",
    "\n",
    "#MERGE BOTH BRANCHES\n",
    "main_merged = concatenate([dropout_2, dropout_3],axis=1)#([dense_seq_2, dense_fps], axis=1)\n",
    "\n",
    "main_dense = Dense(2, activation='softmax')(main_merged)\n",
    "\n",
    "#build and compile model\n",
    "model = Model(inputs=[input_seq, input_fps], outputs=[main_dense])\n",
    "model.compile(loss='categorical_crossentropy', optimizer = adamm, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Training\n",
      "Epoch 1/100\n",
      "1219/1219 [==============================] - 103s 84ms/step - loss: 0.8163 - accuracy: 0.7446 - val_loss: 0.3536 - val_accuracy: 0.7528\n",
      "Epoch 2/100\n",
      "1219/1219 [==============================] - 94s 77ms/step - loss: 0.5094 - accuracy: 0.7755 - val_loss: 0.2929 - val_accuracy: 0.7553\n",
      "Epoch 3/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.5053 - accuracy: 0.7774 - val_loss: 0.7465 - val_accuracy: 0.7607\n",
      "Epoch 4/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5025 - accuracy: 0.7785 - val_loss: 0.6235 - val_accuracy: 0.7601\n",
      "Epoch 5/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5027 - accuracy: 0.7784 - val_loss: 0.2535 - val_accuracy: 0.7625 - loss: 0.5029 - accuracy: 0.77\n",
      "Epoch 6/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5019 - accuracy: 0.7786 - val_loss: 0.5030 - val_accuracy: 0.7616\n",
      "Epoch 7/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5017 - accuracy: 0.7792 - val_loss: 0.5124 - val_accuracy: 0.7635\n",
      "Epoch 8/100\n",
      "1219/1219 [==============================] - 94s 77ms/step - loss: 0.5016 - accuracy: 0.7790 - val_loss: 0.2847 - val_accuracy: 0.7620\n",
      "Epoch 9/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5016 - accuracy: 0.7790 - val_loss: 0.3388 - val_accuracy: 0.7598\n",
      "Epoch 10/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.5000 - accuracy: 0.7787 - val_loss: 0.3027 - val_accuracy: 0.7635\n",
      "Epoch 11/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5012 - accuracy: 0.7783 - val_loss: 0.2056 - val_accuracy: 0.7575\n",
      "Epoch 12/100\n",
      "1219/1219 [==============================] - 96s 78ms/step - loss: 0.4995 - accuracy: 0.7799 - val_loss: 0.0666 - val_accuracy: 0.7580\n",
      "Epoch 13/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.5004 - accuracy: 0.7801 - val_loss: 0.2208 - val_accuracy: 0.7571\n",
      "Epoch 14/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5004 - accuracy: 0.7803 - val_loss: 0.1154 - val_accuracy: 0.7581\n",
      "Epoch 15/100\n",
      "1219/1219 [==============================] - 94s 77ms/step - loss: 0.4987 - accuracy: 0.7806 - val_loss: 0.2422 - val_accuracy: 0.7612\n",
      "Epoch 16/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.5003 - accuracy: 0.7803 - val_loss: 0.1549 - val_accuracy: 0.7568\n",
      "Epoch 17/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4994 - accuracy: 0.7813 - val_loss: 0.7834 - val_accuracy: 0.7586\n",
      "Epoch 18/100\n",
      "1219/1219 [==============================] - 94s 78ms/step - loss: 0.4983 - accuracy: 0.7807 - val_loss: 0.6749 - val_accuracy: 0.7594\n",
      "Epoch 19/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4981 - accuracy: 0.7815 - val_loss: 0.7593 - val_accuracy: 0.7539\n",
      "Epoch 20/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4986 - accuracy: 0.7818 - val_loss: 0.6730 - val_accuracy: 0.7555\n",
      "Epoch 21/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4995 - accuracy: 0.7811 - val_loss: 0.6710 - val_accuracy: 0.7533\n",
      "Epoch 22/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4995 - accuracy: 0.7820 - val_loss: 0.6034 - val_accuracy: 0.7552\n",
      "Epoch 23/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.5003 - accuracy: 0.7808 - val_loss: 0.6392 - val_accuracy: 0.7545\n",
      "Epoch 24/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4998 - accuracy: 0.7802 - val_loss: 0.6620 - val_accuracy: 0.7534\n",
      "Epoch 25/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4997 - accuracy: 0.7825 - val_loss: 0.7295 - val_accuracy: 0.7582\n",
      "Epoch 26/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4990 - accuracy: 0.7811 - val_loss: 0.3150 - val_accuracy: 0.7608\n",
      "Epoch 27/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4997 - accuracy: 0.7814 - val_loss: 0.3151 - val_accuracy: 0.7553\n",
      "Epoch 28/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4993 - accuracy: 0.7815 - val_loss: 0.5995 - val_accuracy: 0.7508\n",
      "Epoch 29/100\n",
      "1219/1219 [==============================] - 95s 78ms/step - loss: 0.4979 - accuracy: 0.7810 - val_loss: 0.4182 - val_accuracy: 0.7449\n",
      "Epoch 30/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4976 - accuracy: 0.7821 - val_loss: 0.3054 - val_accuracy: 0.7548\n",
      "Epoch 31/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4975 - accuracy: 0.7817 - val_loss: 0.5153 - val_accuracy: 0.7556 ETA: 0s - loss: 0.4979 - accuracy: 0.\n",
      "Epoch 32/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4974 - accuracy: 0.7818 - val_loss: 0.6451 - val_accuracy: 0.7509A: 37s - loss: 0.4902 - accuracy - ETA: 37s - loss - ETA: 35s - loss: 0.4959 - accur - ETA: 34s - loss: 0.4954 - ETA: \n",
      "Epoch 33/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4968 - accuracy: 0.7820 - val_loss: 0.6337 - val_accuracy: 0.7547cura\n",
      "Epoch 34/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4961 - accuracy: 0.7825 - val_loss: 0.3086 - val_accuracy: 0.7536\n",
      "Epoch 35/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4968 - accuracy: 0.7818 - val_loss: 0.5498 - val_accuracy: 0.75262s\n",
      "Epoch 36/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4955 - accuracy: 0.7827 - val_loss: 0.5482 - val_accuracy: 0.7465\n",
      "Epoch 37/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4960 - accuracy: 0.7815 - val_loss: 0.4900 - val_accuracy: 0.7434\n",
      "Epoch 38/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4959 - accuracy: 0.7822 - val_loss: 0.4760 - val_accuracy: 0.7401 - loss: 0.4 - ETA: 5 - ETA: 36s - loss: 0. - ETA: 35s - loss: 0.4914  - ETA: 33s - loss: 0.4893 - accuracy: - ETA: \n",
      "Epoch 39/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4953 - accuracy: 0.7824 - val_loss: 0.4263 - val_accuracy: 0.7304 - ET - ETA: 22s - loss: 0.4 - ETA: 20s - loss: 0.49 - ETA: 16s - loss: 0.4960 - accuracy: 0.7\n",
      "Epoch 40/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4953 - accuracy: 0.7824 - val_loss: 0.5562 - val_accuracy: 0.7394\n",
      "Epoch 41/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4943 - accuracy: 0.7835 - val_loss: 0.4363 - val_accuracy: 0.7447A: 16s - loss: 0.4943 - accurac - ETA: 15s - loss: 0.4967 - accuracy: 0.7 - ETA: 15s - loss: 0. - ETA: 13s - loss: 0.4973 - accur -  - ETA: 9s - loss: 0.4956 - accura - ETA: 9s - loss: 0.4958 -  - ETA - ETA: 2s - loss: 0.4914 \n",
      "Epoch 42/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4953 - accuracy: 0.7828 - val_loss: 0.3196 - val_accuracy: 0.7469\n",
      "Epoch 43/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4939 - accuracy: 0.7840 - val_loss: 0.5379 - val_accuracy: 0.7529\n",
      "Epoch 44/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4954 - accuracy: 0.7829 - val_loss: 0.6674 - val_accuracy: 0.7515\n",
      "Epoch 45/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4951 - accuracy: 0.7828 - val_loss: 0.5620 - val_accuracy: 0.7492\n",
      "Epoch 46/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4937 - accuracy: 0.7843 - val_loss: 0.4139 - val_accuracy: 0.75040s - loss: 0.4938 - accuracy: 0.78\n",
      "Epoch 47/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4953 - accuracy: 0.7824 - val_loss: 0.1855 - val_accuracy: 0.7507\n",
      "Epoch 48/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4946 - accuracy: 0.7836 - val_loss: 0.5845 - val_accuracy: 0.7468\n",
      "Epoch 49/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4938 - accuracy: 0.7839 - val_loss: 0.5190 - val_accuracy: 0.7381curacy: 0.\n",
      "Epoch 50/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4942 - accuracy: 0.7843 - val_loss: 0.4791 - val_accuracy: 0.7383 - loss: 0.4927 - accuracy:  - ETA: 0s - loss: 0.4928 - \n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4930 - accuracy: 0.7838 - val_loss: 0.6775 - val_accuracy: 0.7456\n",
      "Epoch 52/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4933 - accuracy: 0.7831 - val_loss: 0.3709 - val_accuracy: 0.7415\n",
      "Epoch 53/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4934 - accuracy: 0.7823 - val_loss: 0.4779 - val_accuracy: 0.7239\n",
      "Epoch 54/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4952 - accuracy: 0.7819 - val_loss: 0.6000 - val_accuracy: 0.7453\n",
      "Epoch 55/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4924 - accuracy: 0.7842 - val_loss: 0.2634 - val_accuracy: 0.7446\n",
      "Epoch 56/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4930 - accuracy: 0.7832 - val_loss: 0.5543 - val_accuracy: 0.7424\n",
      "Epoch 57/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4937 - accuracy: 0.7839 - val_loss: 0.1459 - val_accuracy: 0.7437\n",
      "Epoch 58/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4919 - accuracy: 0.7836 - val_loss: 0.3248 - val_accuracy: 0.7462\n",
      "Epoch 59/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4932 - accuracy: 0.7839 - val_loss: 0.6266 - val_accuracy: 0.7373\n",
      "Epoch 60/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4924 - accuracy: 0.7840 - val_loss: 0.7696 - val_accuracy: 0.7360\n",
      "Epoch 61/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4939 - accuracy: 0.7835 - val_loss: 0.8136 - val_accuracy: 0.7444\n",
      "Epoch 62/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4928 - accuracy: 0.7840 - val_loss: 0.6616 - val_accuracy: 0.7450\n",
      "Epoch 63/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4939 - accuracy: 0.7840 - val_loss: 0.6643 - val_accuracy: 0.7377s: 0.488 - ETA: 55s - loss: 0.4913 - accurac - ETA: 54s - loss: 0.4918 -  - ETA: 53s - loss: 0.4901 - a - ETA: 52s - loss: 0.490 - ETA: 50s - loss: - ETA: 42s - loss: 0. -\n",
      "Epoch 64/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4929 - accuracy: 0.7846 - val_loss: 0.6453 - val_accuracy: 0.7302\n",
      "Epoch 65/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4932 - accuracy: 0.7829 - val_loss: 0.6705 - val_accuracy: 0.7198\n",
      "Epoch 66/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4932 - accuracy: 0.7835 - val_loss: 0.5736 - val_accuracy: 0.7198\n",
      "Epoch 67/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4948 - accuracy: 0.7830 - val_loss: 0.6286 - val_accuracy: 0.7262\n",
      "Epoch 68/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4935 - accuracy: 0.7840 - val_loss: 0.5328 - val_accuracy: 0.7428 - a - ETA: 40s - loss:\n",
      "Epoch 69/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4960 - accuracy: 0.7824 - val_loss: 0.6301 - val_accuracy: 0.7294\n",
      "Epoch 70/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4923 - accuracy: 0.7830 - val_loss: 0.4820 - val_accuracy: 0.7253 ETA: 23s - loss: 0.4960 - accuracy:\n",
      "Epoch 71/100\n",
      "1219/1219 [==============================] - 97s 79ms/step - loss: 0.4940 - accuracy: 0.7836 - val_loss: 0.6316 - val_accuracy: 0.7384\n",
      "Epoch 72/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4943 - accuracy: 0.7843 - val_loss: 0.4682 - val_accuracy: 0.7408\n",
      "Epoch 73/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4932 - accuracy: 0.7841 - val_loss: 0.2684 - val_accuracy: 0.7321\n",
      "Epoch 74/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4940 - accuracy: 0.7829 - val_loss: 0.3359 - val_accuracy: 0.7364\n",
      "Epoch 75/100\n",
      "1219/1219 [==============================] - 99s 82ms/step - loss: 0.4946 - accuracy: 0.7841 - val_loss: 0.4182 - val_accuracy: 0.7135\n",
      "Epoch 76/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4931 - accuracy: 0.7837 - val_loss: 0.4323 - val_accuracy: 0.7165\n",
      "Epoch 77/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4936 - accuracy: 0.7839 - val_loss: 0.5971 - val_accuracy: 0.7209\n",
      "Epoch 78/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4941 - accuracy: 0.7846 - val_loss: 0.4116 - val_accuracy: 0.7428\n",
      "Epoch 79/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4932 - accuracy: 0.7843 - val_loss: 0.3408 - val_accuracy: 0.7342\n",
      "Epoch 80/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4932 - accuracy: 0.7843 - val_loss: 0.5816 - val_accuracy: 0.7479A: 42s - loss: - ETA: 40s - loss: 0.4950 - accu - ETA: 39s - loss: 0.4940 -  - ETA: 38s - l\n",
      "Epoch 81/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4932 - accuracy: 0.7843 - val_loss: 0.5848 - val_accuracy: 0.7450\n",
      "Epoch 82/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4938 - accuracy: 0.7838 - val_loss: 0.3863 - val_accuracy: 0.7508\n",
      "Epoch 83/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4950 - accuracy: 0.7830 - val_loss: 0.4849 - val_accuracy: 0.7481\n",
      "Epoch 84/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4936 - accuracy: 0.7831 - val_loss: 0.6249 - val_accuracy: 0.7530\n",
      "Epoch 85/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4934 - accuracy: 0.7838 - val_loss: 0.5886 - val_accuracy: 0.7460\n",
      "Epoch 86/100\n",
      "1219/1219 [==============================] - 99s 82ms/step - loss: 0.4957 - accuracy: 0.7825 - val_loss: 0.7261 - val_accuracy: 0.7534 4s - loss: 0.502 - ETA: 3s - los - ETA: 2s - l - ETA: 1s -\n",
      "Epoch 87/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4942 - accuracy: 0.7836 - val_loss: 0.5563 - val_accuracy: 0.7427\n",
      "Epoch 88/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4946 - accuracy: 0.7838 - val_loss: 0.4719 - val_accuracy: 0.7462\n",
      "Epoch 89/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4937 - accuracy: 0.7849 - val_loss: 0.6688 - val_accuracy: 0.7102\n",
      "Epoch 90/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4944 - accuracy: 0.7833 - val_loss: 0.8029 - val_accuracy: 0.7249\n",
      "Epoch 91/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4927 - accuracy: 0.7843 - val_loss: 0.7277 - val_accuracy: 0.75237s - loss: 0.4946 - - ETA: 36s - loss: 0. - ETA: 34 - ETA: 28s - loss: 0.4960 - accuracy - ETA: 27s - los - ETA: 25s - l - ETA: 23s - loss - ETA: 1 - ETA: 4s - loss: 0.4 - ETA: 3s - loss: 0.4 - ETA: 2s - loss: 0\n",
      "Epoch 92/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4937 - accuracy: 0.7829 - val_loss: 0.7861 - val_accuracy: 0.4997\n",
      "Epoch 93/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4943 - accuracy: 0.7831 - val_loss: 0.6573 - val_accuracy: 0.7265\n",
      "Epoch 94/100\n",
      "1219/1219 [==============================] - 99s 81ms/step - loss: 0.4937 - accuracy: 0.7829 - val_loss: 1.2001 - val_accuracy: 0.72850 - ETA: 47s - loss: 0.4953 - accurac - - ETA: 36s - loss: 0.4959 - accu - ETA: 29s - loss: 0.49 - ETA: 27s - loss:  - ETA: 25s - loss: 0.5000 - accur - ETA: 24s - loss: 0.5008 - accuracy: 0.775 - ETA: 21s - loss: 0.4988 - accur - ETA: 0s - loss: 0.4943 - accura\n",
      "Epoch 95/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4924 - accuracy: 0.7838 - val_loss: 0.9706 - val_accuracy: 0.6997oss: 0.4926 - - ETA: 31 - ETA: 28s - loss: 0.4931 - accur - ETA: - ETA: 25s - loss: 0.4980 - accuracy: 0.7 - ETA: 24s - loss: 0.4985 - acc - ETA: 0s - loss: 0.4926 - accuracy: 0.\n",
      "Epoch 96/100\n",
      "1219/1219 [==============================] - 98s 81ms/step - loss: 0.4932 - accuracy: 0.7838 - val_loss: 0.9292 - val_accuracy: 0.7220\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4923 - accuracy: 0.7836 - val_loss: 0.5502 - val_accuracy: 0.7065\n",
      "Epoch 98/100\n",
      "1219/1219 [==============================] - 96s 79ms/step - loss: 0.4939 - accuracy: 0.7842 - val_loss: 0.6356 - val_accuracy: 0.7289\n",
      "Epoch 99/100\n",
      "1219/1219 [==============================] - 97s 80ms/step - loss: 0.4940 - accuracy: 0.7844 - val_loss: 0.9037 - val_accuracy: 0.6763TA: 30s - loss: 0.4954 - ETA: 25s - loss: 0.49 - ETA: 17s - loss: 0.4987 - accuracy: 0.779 - ETA: 17s - loss: 0.4989 - accuracy - ETA: 16s - loss: 0.4993 - accuracy: 0.7 - ETA: 16s - lo - ETA: 14s - loss: 0.49 - ETA: 1\n",
      "Epoch 100/100\n",
      "1219/1219 [==============================] - 98s 80ms/step - loss: 0.4956 - accuracy: 0.7828 - val_loss: 0.5813 - val_accuracy: 0.6877\n",
      "Prediction on test data\n",
      "best epoch:  007\n",
      "Counting predicted:  Counter({1: 20256, 0: 879})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7805\n",
      "Confusion matrix:\n",
      "[[  552  4313]\n",
      " [  327 15943]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.11      0.19      4865\n",
      "           1       0.79      0.98      0.87     16270\n",
      "\n",
      "    accuracy                           0.78     21135\n",
      "   macro avg       0.71      0.55      0.53     21135\n",
      "weighted avg       0.75      0.78      0.72     21135\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.717026\n",
      "Fold: 1\n",
      "Training\n",
      "Epoch 1/100\n",
      "1241/1241 [==============================] - 98s 79ms/step - loss: 0.5024 - accuracy: 0.7761 - val_loss: 0.5243 - val_accuracy: 0.7845\n",
      "Epoch 2/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.5009 - accuracy: 0.7770 - val_loss: 0.5223 - val_accuracy: 0.7852\n",
      "Epoch 3/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.5002 - accuracy: 0.7776 - val_loss: 0.5551 - val_accuracy: 0.7825\n",
      "Epoch 4/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.5018 - accuracy: 0.7764 - val_loss: 0.5761 - val_accuracy: 0.7855\n",
      "Epoch 5/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.5000 - accuracy: 0.7767 - val_loss: 0.4897 - val_accuracy: 0.7858\n",
      "Epoch 6/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4992 - accuracy: 0.7778 - val_loss: 0.4571 - val_accuracy: 0.7859: 1:01 - - ETA: \n",
      "Epoch 7/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4987 - accuracy: 0.7772 - val_loss: 0.4378 - val_accuracy: 0.7876 0.4993 - accuracy: 0.\n",
      "Epoch 8/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4988 - accuracy: 0.7777 - val_loss: 0.6949 - val_accuracy: 0.7871 - ETA: 27s - loss: 0.5029 - a - ETA: 26s - loss: 0.5006 - accuracy: 0.77 - ETA: 26s - loss: 0.5003 - accur - ETA: 25s - loss: 0.4992 - accuracy: 0.7 - ETA\n",
      "Epoch 9/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4984 - accuracy: 0.7786 - val_loss: 1.8015 - val_accuracy: 0.7858\n",
      "Epoch 10/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4978 - accuracy: 0.7797 - val_loss: 0.2055 - val_accuracy: 0.7871 \n",
      "Epoch 11/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4975 - accuracy: 0.7794 - val_loss: 0.2412 - val_accuracy: 0.7863.49 -\n",
      "Epoch 12/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4983 - accuracy: 0.7789 - val_loss: 0.2361 - val_accuracy: 0.78090 - ETA: 23s - loss: 0.497 - ETA:  - ETA: 1s - loss: 0.4989 - accuracy - ETA: 1s - los - ETA: 0s - loss: 0.4983 - accuracy: \n",
      "Epoch 13/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4990 - accuracy: 0.7800 - val_loss: 0.1573 - val_accuracy: 0.7831ss: 0 - ETA: 5s - loss: 0.4964 - accu\n",
      "Epoch 14/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4961 - accuracy: 0.7802 - val_loss: 0.0132 - val_accuracy: 0.7833\n",
      "Epoch 15/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4976 - accuracy: 0.7800 - val_loss: 0.7440 - val_accuracy: 0.7795\n",
      "Epoch 16/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4982 - accuracy: 0.7781 - val_loss: 0.5718 - val_accuracy: 0.7864\n",
      "Epoch 17/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4992 - accuracy: 0.7797 - val_loss: 0.4882 - val_accuracy: 0.7844\n",
      "Epoch 18/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4979 - accuracy: 0.7794 - val_loss: 0.4023 - val_accuracy: 0.7871\n",
      "Epoch 19/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4973 - accuracy: 0.7799 - val_loss: 0.2621 - val_accuracy: 0.7838TA: 37s - loss: 0.4 - ETA: 36s - loss: 0.4906 - accuracy:  - ETA: 35s - loss: 0.4887 - accuracy: 0.786 - ETA: 35s - loss: 0.4882 - accuracy: 0 - ETA: 35s - loss: 0.4866 - ac - ETA: 34s - loss: 0.48\n",
      "Epoch 20/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4985 - accuracy: 0.7789 - val_loss: 0.4849 - val_accuracy: 0.7839\n",
      "Epoch 21/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4971 - accuracy: 0.7802 - val_loss: 0.3703 - val_accuracy: 0.783900 - accuracy:  - ETA: 12s - loss: 0.4997 - accuracy: 0.778 - ETA: -\n",
      "Epoch 22/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4970 - accuracy: 0.7805 - val_loss: 0.6131 - val_accuracy: 0.7869\n",
      "Epoch 23/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4978 - accuracy: 0.7784 - val_loss: 0.6895 - val_accuracy: 0.7856\n",
      "Epoch 24/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4986 - accuracy: 0.7791 - val_loss: 0.8377 - val_accuracy: 0.7820 - ETA: 25s - loss: 0 - ETA: 24s - loss: 0.5003 - accura - ETA: 23s - loss: 0.4994 - accuracy: 0.776 - ETA: 19s - loss: 0.4990 - accuracy: 0 - ETA: 19s - loss: 0.4997 - accuracy: 0 - ETA: 19s - loss: 0.5000 - accuracy: 0.7 - ETA: 18s - loss: \n",
      "Epoch 25/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4989 - accuracy: 0.7796 - val_loss: 0.4317 - val_accuracy: 0.7867\n",
      "Epoch 26/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4956 - accuracy: 0.7801 - val_loss: 0.3737 - val_accuracy: 0.7848\n",
      "Epoch 27/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4947 - accuracy: 0.7804 - val_loss: 0.1810 - val_accuracy: 0.7852\n",
      "Epoch 28/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4954 - accuracy: 0.7809 - val_loss: 0.2468 - val_accuracy: 0.7825\n",
      "Epoch 29/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4963 - accuracy: 0.7801 - val_loss: 0.5508 - val_accuracy: 0.7809\n",
      "Epoch 30/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4962 - accuracy: 0.7796 - val_loss: 0.1463 - val_accuracy: 0.7848\n",
      "Epoch 31/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4941 - accuracy: 0.7800 - val_loss: 0.6670 - val_accuracy: 0.7851\n",
      "Epoch 32/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4947 - accuracy: 0.7803 - val_loss: 0.5675 - val_accuracy: 0.7880 accura - ETA: 55s - los - ETA: 19s - loss: 0.4931  - ETA: 6s - - ETA: 4s - loss: 0.4918 - accuracy:  - E\n",
      "Epoch 33/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4970 - accuracy: 0.7795 - val_loss: 0.6819 - val_accuracy: 0.7848loss: 0.4937 - - ETA: 2 - ETA: 17s - loss: 0.4986 - ETA: 4s - loss: 0.4947 - accura - E\n",
      "Epoch 34/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4942 - accuracy: 0.7799 - val_loss: 0.5924 - val_accuracy: 0.7838\n",
      "Epoch 35/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4951 - accuracy: 0.7805 - val_loss: 0.4983 - val_accuracy: 0.7828 - loss: - ETA: 49s - loss: 0.4806 - accur - ETA:  - ETA: 23s - - ETA: 21s - loss: 0.4926\n",
      "Epoch 36/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4949 - accuracy: 0.7802 - val_loss: 0.3758 - val_accuracy: 0.7811\n",
      "Epoch 37/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4953 - accuracy: 0.7798 - val_loss: 0.5770 - val_accuracy: 0.7799\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4946 - accuracy: 0.7809 - val_loss: 0.2471 - val_accuracy: 0.7852\n",
      "Epoch 39/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4936 - accuracy: 0.7808 - val_loss: 0.6369 - val_accuracy: 0.7808\n",
      "Epoch 40/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4951 - accuracy: 0.7797 - val_loss: 0.1659 - val_accuracy: 0.7795\n",
      "Epoch 41/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4928 - accuracy: 0.7811 - val_loss: 0.3171 - val_accuracy: 0.7813\n",
      "Epoch 42/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4935 - accuracy: 0.7811 - val_loss: 0.5089 - val_accuracy: 0.7789\n",
      "Epoch 43/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4948 - accuracy: 0.7804 - val_loss: 0.6533 - val_accuracy: 0.7800\n",
      "Epoch 44/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4960 - accuracy: 0.7807 - val_loss: 0.9852 - val_accuracy: 0.7789\n",
      "Epoch 45/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4935 - accuracy: 0.7813 - val_loss: 0.6006 - val_accuracy: 0.7827ss: 0.4773 - accurac - ETA: 47 - ETA: - ETA: 42s - loss: 0.4883 -  - ETA: - ETA: 38s - loss: 0.4835 - accuracy: 0.78 - ETA: 38s - loss: 0.4822 - accuracy: - ETA: 37s - loss: 0. - ETA: 22s - loss: 0.4933 - accuracy: 0. - ETA: 22s - loss: 0.4924 - a - ETA: 2\n",
      "Epoch 46/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4946 - accuracy: 0.7808 - val_loss: 0.8362 - val_accuracy: 0.7748A: 31s - loss: 0.4913 - ac - ETA: 27s - loss: 0.4979 - ETA: 25 - ETA: 13s - loss: 0.4974 - accura - ETA: 12 - ETA: 1s - loss: 0.4929 - accuracy: 0.78 - ETA: \n",
      "Epoch 47/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4942 - accuracy: 0.7803 - val_loss: 1.2041 - val_accuracy: 0.7688\n",
      "Epoch 48/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4949 - accuracy: 0.7803 - val_loss: 0.6844 - val_accuracy: 0.7707\n",
      "Epoch 49/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4948 - accuracy: 0.7794 - val_loss: 0.4568 - val_accuracy: 0.7505 40s - loss: 0.4890 - ET - ETA: 0s - loss: 0.4943 - \n",
      "Epoch 50/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4946 - accuracy: 0.7802 - val_loss: 0.6109 - val_accuracy: 0.7491709 -  - ETA: 1:08 - loss: 0.4674 - ac - ETA: 1:03 - - ETA: 23s - loss: 0.4959 - accur - ETA: 22s - loss: 0. - ETA: 0s - loss: 0.4947 - accuracy: \n",
      "Epoch 51/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4942 - accuracy: 0.7806 - val_loss: 0.6238 - val_accuracy: 0.75486s - loss: 0.4964 - accuracy: 0.777 - ETA: 16s - loss: 0.4966 - a - ETA: 15s - loss: 0.4968 - acc - ETA: 14s - ETA: 12s - loss: 0.4962 - accuracy - - ETA: 9s - l - E - ETA: 5s - los - ETA: 0s - loss: 0.4928 - ac - ETA: 0s - loss: 0.4939 - accuracy: 0.\n",
      "Epoch 52/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4945 - accuracy: 0.7808 - val_loss: 0.5912 - val_accuracy: 0.7640\n",
      "Epoch 53/100\n",
      "1241/1241 [==============================] - 96s 78ms/step - loss: 0.4939 - accuracy: 0.7795 - val_loss: 0.5241 - val_accuracy: 0.7490A: 0s - loss: 0.492\n",
      "Epoch 54/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4944 - accuracy: 0.7801 - val_loss: 0.5934 - val_accuracy: 0.7564.4914 - accu - ETA: 2s - loss: 0.490 - E\n",
      "Epoch 55/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4934 - accuracy: 0.7806 - val_loss: 0.3012 - val_accuracy: 0.7575\n",
      "Epoch 56/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4936 - accuracy: 0.7807 - val_loss: 0.3922 - val_accuracy: 0.7465\n",
      "Epoch 57/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4929 - accuracy: 0.7810 - val_loss: 0.8569 - val_accuracy: 0.7464 accuracy: 0.7 - ETA: 34s - loss: 0.4888 - accuracy: 0.783 - ETA: 34s - l - ETA: 32s - loss: 0.4846 - accur - ETA: 31s - loss: 0.4862 - ac - ETA: 30s - loss: 0.4890 - accuracy:  - ETA: 30s - loss: 0.4906 - accuracy: 0.780 - ETA: 30s - loss: 0.4907 - acc\n",
      "Epoch 58/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4931 - accuracy: 0.7801 - val_loss: 0.4314 - val_accuracy: 0.7432\n",
      "Epoch 59/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4931 - accuracy: 0.7814 - val_loss: 0.3211 - val_accuracy: 0.7517\n",
      "Epoch 60/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4923 - accuracy: 0.7817 - val_loss: 0.0858 - val_accuracy: 0.7504accu\n",
      "Epoch 61/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4935 - accuracy: 0.7810 - val_loss: 0.4102 - val_accuracy: 0.7447\n",
      "Epoch 62/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4935 - accuracy: 0.7809 - val_loss: 0.8231 - val_accuracy: 0.7341: 50s - loss: 0.4807 -  - ETA: 49s - loss: 0.4817 - ac - ETA: 44s - loss: 0.4849 - accuracy: 0\n",
      "Epoch 63/100\n",
      "1241/1241 [==============================] - 96s 78ms/step - loss: 0.4933 - accuracy: 0.7810 - val_loss: 0.5792 - val_accuracy: 0.7170\n",
      "Epoch 64/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4925 - accuracy: 0.7815 - val_loss: 0.6101 - val_accuracy: 0.7226TA: 40s - -  - ETA: 34s - lo - ETA: 32s - loss: 0.4865 - - ETA: 24s - loss: 0 \n",
      "Epoch 65/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4921 - accuracy: 0.7822 - val_loss: 0.3804 - val_accuracy: 0.7579\n",
      "Epoch 66/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4945 - accuracy: 0.7808 - val_loss: 0.6586 - val_accuracy: 0.7506.4867 -  - ETA: 30s  - ETA: 24s - loss: 0.4999 - accurac - ETA: 0s - loss: 0.4944 - accuracy: \n",
      "Epoch 67/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4924 - accuracy: 0.7811 - val_loss: 0.7752 - val_accuracy: 0.7558\n",
      "Epoch 68/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4943 - accuracy: 0.7804 - val_loss: 0.4287 - val_accuracy: 0.7540\n",
      "Epoch 69/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4944 - accuracy: 0.7810 - val_loss: 0.7309 - val_accuracy: 0.7558acy:  - ETA: 54s - loss: 0.4830 - accur - E - ETA: 50s - l\n",
      "Epoch 70/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4933 - accuracy: 0.7814 - val_loss: 0.6050 - val_accuracy: 0.7631\n",
      "Epoch 71/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4942 - accuracy: 0.7814 - val_loss: 0.5922 - val_accuracy: 0.7742\n",
      "Epoch 72/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4937 - accuracy: 0.7811 - val_loss: 0.6266 - val_accuracy: 0.7638\n",
      "Epoch 73/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4924 - accuracy: 0.7815 - val_loss: 0.4581 - val_accuracy: 0.7737s - loss: 0.4873 - accurac - ETA: 44s - loss: 0.4871 - accuracy: 0. - ETA: 43s - loss: 0. - ETA: 12s - loss - ETA: 6s - - ETA: 5s - loss: 0.4963 -  - ETA: 4s - loss: 0.4977 - accuracy - ETA: 2s -\n",
      "Epoch 74/100\n",
      "1241/1241 [==============================] - 96s 78ms/step - loss: 0.4933 - accuracy: 0.7814 - val_loss: 0.2893 - val_accuracy: 0.7739\n",
      "Epoch 75/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4919 - accuracy: 0.7819 - val_loss: 0.4036 - val_accuracy: 0.7771 - ETA: 54s - lo - ETA: 52s - loss: 0.4786 - ETA: 50s - loss: 0.4847 - accuracy: 0.786 - ETA: 50s - loss: 0.484 - ETA: 32s - los - ETA: 23s - loss: 0.4981 - accu - ETA: 22s - lo - ETA: 20s - loss: 0.4956 - accur - ETA: 19s - loss: 0.4945 - ETA - ETA: 14s - loss: 0.49 - ETA: 1s - loss: 0 - ETA: 1s - l\n",
      "Epoch 76/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4919 - accuracy: 0.7815 - val_loss: 0.1057 - val_accuracy: 0.7816: 1s - loss: 0.4912 - accuracy - ETA: \n",
      "Epoch 77/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4908 - accuracy: 0.7825 - val_loss: 0.6299 - val_accuracy: 0.7827\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4928 - accuracy: 0.7816 - val_loss: 0.6540 - val_accuracy: 0.7805\n",
      "Epoch 79/100\n",
      "1241/1241 [==============================] - 94s 76ms/step - loss: 0.4910 - accuracy: 0.7831 - val_loss: 0.2175 - val_accuracy: 0.7766\n",
      "Epoch 80/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4922 - accuracy: 0.7821 - val_loss: 0.1838 - val_accuracy: 0.7742 loss: 0.4963 - accuracy:  - ETA: 21s - loss: 0.4952 - accuracy - ETA: 20s - loss: 0.495 - ETA: 19s - loss: 0.4945 - accuracy: 0.7 - ETA: 19s - loss: 0.4944 - accuracy:  - ETA: 18s - \n",
      "Epoch 81/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4902 - accuracy: 0.7832 - val_loss: 0.2711 - val_accuracy: 0.7769 0.4818 - acc - ETA: 52s - loss: 0 - ETA: 43s - loss: - ETA: 41s - loss: 0.4905 - accurac - ETA: 40s - lo - ETA: 38s - loss: 0.4 - ETA: 36s - loss: 0.4873 - ac - ETA: 35s - loss: 0.4871 - accuracy:  - E - ETA: 1s - loss:\n",
      "Epoch 82/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4911 - accuracy: 0.7825 - val_loss: 0.5059 - val_accuracy: 0.7834\n",
      "Epoch 83/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4929 - accuracy: 0.7822 - val_loss: 0.3667 - val_accuracy: 0.7809\n",
      "Epoch 84/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4919 - accuracy: 0.7821 - val_loss: 0.6068 - val_accuracy: 0.7832\n",
      "Epoch 85/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4907 - accuracy: 0.7829 - val_loss: 0.5597 - val_accuracy: 0.7844\n",
      "Epoch 86/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4910 - accuracy: 0.7830 - val_loss: 0.1912 - val_accuracy: 0.7820\n",
      "Epoch 87/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4911 - accuracy: 0.7820 - val_loss: 0.5206 - val_accuracy: 0.777288 -  - ETA: 30s - loss: 0.4857 - - ETA: 4s - loss: 0.4960 - accuracy:  - ETA - E\n",
      "Epoch 88/100\n",
      "1241/1241 [==============================] - 96s 78ms/step - loss: 0.4918 - accuracy: 0.7824 - val_loss: 0.6300 - val_accuracy: 0.7825\n",
      "Epoch 89/100\n",
      "1241/1241 [==============================] - 95s 77ms/step - loss: 0.4899 - accuracy: 0.7826 - val_loss: 0.2088 - val_accuracy: 0.7866 loss: 0.487 - ETA: 32s - loss: 0.4895 - accurac - ETA: 31s - loss: 0.48 - ETA: 29s - loss: 0.  - ETA: 25s - loss: 0.4942 - accuracy:  - ETA: 24s - loss: 0 - ETA: 20s - loss: 0.4943 - accuracy: 0 - ETA: 4s - loss: 0.4948 - accuracy:  - ETA: 4s\n",
      "Epoch 90/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4923 - accuracy: 0.7819 - val_loss: 0.3022 - val_accuracy: 0.7841\n",
      "Epoch 91/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4920 - accuracy: 0.7820 - val_loss: 0.6126 - val_accuracy: 0.7818-  - ETA: 0s - loss: 0.4917 - accuracy\n",
      "Epoch 92/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4923 - accuracy: 0.7827 - val_loss: 0.7479 - val_accuracy: 0.7870TA: 1s - loss: 0.4936 - accura - ETA: 1s - loss: 0.4931 -  - ETA: 0s - loss: 0.4919 - accu\n",
      "Epoch 93/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4924 - accuracy: 0.7818 - val_loss: 0.4305 - val_accuracy: 0.7850\n",
      "Epoch 94/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4928 - accuracy: 0.7816 - val_loss: 0.4431 - val_accuracy: 0.7832 0.480 - ETA: 48s - loss: \n",
      "Epoch 95/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4919 - accuracy: 0.7827 - val_loss: 0.4704 - val_accuracy: 0.7854 - loss: 0.4826 - accuracy: 0.7 - ETA: 49s - l - ETA: 47s - loss: 0.4848 - accuracy: - ETA: 46s - loss: 0.4865 - accuracy: 0 - ETA: 46s - loss: 0.4854 - accuracy: - ETA: 46s - loss: 0.4859 - ac - ETA: 42s - loss: 0.4883 - accura - ETA: 41s - loss: 0.4908 - acc - ETA: 40s - loss: 0.4943 -  - ETA: 39s - loss: 0.4933 - accuracy - ETA: 38s \n",
      "Epoch 96/100\n",
      "1241/1241 [==============================] - 95s 76ms/step - loss: 0.4910 - accuracy: 0.7832 - val_loss: 0.3385 - val_accuracy: 0.7841\n",
      "Epoch 97/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4912 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7809\n",
      "Epoch 98/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4910 - accuracy: 0.7829 - val_loss: 0.4997 - val_accuracy: 0.7778loss: 0.4906 - accuracy:  - ETA: 24s - loss:\n",
      "Epoch 99/100\n",
      "1241/1241 [==============================] - 96s 77ms/step - loss: 0.4892 - accuracy: 0.7832 - val_loss: 0.6087 - val_accuracy: 0.7643: 1s\n",
      "Epoch 100/100\n",
      "1241/1241 [==============================] - 98s 79ms/step - loss: 0.4908 - accuracy: 0.7829 - val_loss: 0.8054 - val_accuracy: 0.7688\n",
      "Prediction on test data\n",
      "best epoch:  032\n",
      "Counting predicted:  Counter({1: 19820, 0: 1628})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7855\n",
      "Confusion matrix:\n",
      "[[  994  3966]\n",
      " [  634 15854]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.20      0.30      4960\n",
      "           1       0.80      0.96      0.87     16488\n",
      "\n",
      "    accuracy                           0.79     21448\n",
      "   macro avg       0.71      0.58      0.59     21448\n",
      "weighted avg       0.76      0.79      0.74     21448\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.702878\n",
      "Fold: 2\n",
      "Training\n",
      "Epoch 1/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4950 - accuracy: 0.7814 - val_loss: 0.5430 - val_accuracy: 0.7907\n",
      "Epoch 2/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4947 - accuracy: 0.7824 - val_loss: 0.3706 - val_accuracy: 0.7907\n",
      "Epoch 3/100\n",
      "1249/1249 [==============================] - 102s 82ms/step - loss: 0.4952 - accuracy: 0.7821 - val_loss: 0.3481 - val_accuracy: 0.7899\n",
      "Epoch 4/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4931 - accuracy: 0.7818 - val_loss: 0.7633 - val_accuracy: 0.7891\n",
      "Epoch 5/100\n",
      "1249/1249 [==============================] - 103s 82ms/step - loss: 0.4928 - accuracy: 0.7830 - val_loss: 0.4335 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4913 - accuracy: 0.7832 - val_loss: 0.9828 - val_accuracy: 0.7868- loss: 0.4920 - accuracy\n",
      "Epoch 7/100\n",
      "1249/1249 [==============================] - 102s 81ms/step - loss: 0.4913 - accuracy: 0.7829 - val_loss: 0.5130 - val_accuracy: 0.7892\n",
      "Epoch 8/100\n",
      "1249/1249 [==============================] - 102s 81ms/step - loss: 0.4897 - accuracy: 0.7833 - val_loss: 0.4787 - val_accuracy: 0.7836\n",
      "Epoch 9/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4888 - accuracy: 0.7835 - val_loss: 0.7489 - val_accuracy: 0.7726\n",
      "Epoch 10/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4897 - accuracy: 0.7844 - val_loss: 0.3415 - val_accuracy: 0.7841\n",
      "Epoch 11/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4903 - accuracy: 0.7833 - val_loss: 0.3014 - val_accuracy: 0.7825 lo\n",
      "Epoch 12/100\n",
      "1249/1249 [==============================] - 99s 80ms/step - loss: 0.4913 - accuracy: 0.7828 - val_loss: 0.6659 - val_accuracy: 0.78600.4961 - accuracy: 0.77 - ETA - ETA: 22s - lo - ETA: 19s - loss: 0. - ETA: 7s - loss: 0.497 - ETA: 6s - loss: 0.4958 - accura - ETA: 2s -\n",
      "Epoch 13/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4915 - accuracy: 0.7829 - val_loss: 0.6287 - val_accuracy: 0.7847\n",
      "Epoch 14/100\n",
      "1249/1249 [==============================] - 97s 78ms/step - loss: 0.4907 - accuracy: 0.7831 - val_loss: 0.7060 - val_accuracy: 0.7686\n",
      "Epoch 15/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4909 - accuracy: 0.7832 - val_loss: 0.6592 - val_accuracy: 0.7877\n",
      "Epoch 16/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4915 - accuracy: 0.7814 - val_loss: 0.6678 - val_accuracy: 0.7847\n",
      "Epoch 17/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4896 - accuracy: 0.7842 - val_loss: 0.5258 - val_accuracy: 0.7778\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4893 - accuracy: 0.7834 - val_loss: 0.4837 - val_accuracy: 0.7719\n",
      "Epoch 19/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4895 - accuracy: 0.7843 - val_loss: 0.3400 - val_accuracy: 0.7773\n",
      "Epoch 20/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4883 - accuracy: 0.7837 - val_loss: 0.3635 - val_accuracy: 0.7698\n",
      "Epoch 21/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4888 - accuracy: 0.7846 - val_loss: 0.2406 - val_accuracy: 0.7782 - accuracy\n",
      "Epoch 22/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4884 - accuracy: 0.7844 - val_loss: 0.4558 - val_accuracy: 0.7754\n",
      "Epoch 23/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4870 - accuracy: 0.7853 - val_loss: 0.3166 - val_accuracy: 0.7688\n",
      "Epoch 24/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4884 - accuracy: 0.7832 - val_loss: 0.4309 - val_accuracy: 0.7753\n",
      "Epoch 25/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4883 - accuracy: 0.7844 - val_loss: 0.7442 - val_accuracy: 0.7597 47s - loss: 0.4873 - accuracy\n",
      "Epoch 26/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4882 - accuracy: 0.7841 - val_loss: 0.4457 - val_accuracy: 0.7869 - loss: 0.4933 - accuracy: 0. - ETA: 6s - ETA: 4s\n",
      "Epoch 27/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4873 - accuracy: 0.7844 - val_loss: 0.5690 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4876 - accuracy: 0.7842 - val_loss: 0.5493 - val_accuracy: 0.7886\n",
      "Epoch 29/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4887 - accuracy: 0.7843 - val_loss: 0.6815 - val_accuracy: 0.7737\n",
      "Epoch 30/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4889 - accuracy: 0.7844 - val_loss: 0.6896 - val_accuracy: 0.7665\n",
      "Epoch 31/100\n",
      "1249/1249 [==============================] - 97s 78ms/step - loss: 0.4899 - accuracy: 0.7834 - val_loss: 0.7193 - val_accuracy: 0.7310\n",
      "Epoch 32/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4882 - accuracy: 0.7836 - val_loss: 0.9354 - val_accuracy: 0.7622\n",
      "Epoch 33/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4883 - accuracy: 0.7839 - val_loss: 0.6642 - val_accuracy: 0.7901\n",
      "Epoch 34/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4893 - accuracy: 0.7839 - val_loss: 0.3282 - val_accuracy: 0.7900\n",
      "Epoch 35/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4868 - accuracy: 0.7849 - val_loss: 0.4724 - val_accuracy: 0.7728\n",
      "Epoch 36/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4880 - accuracy: 0.7841 - val_loss: 0.4619 - val_accuracy: 0.7858 - loss: 0.4880 \n",
      "Epoch 37/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4881 - accuracy: 0.7836 - val_loss: 0.5143 - val_accuracy: 0.7859\n",
      "Epoch 38/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4876 - accuracy: 0.7844 - val_loss: 0.8285 - val_accuracy: 0.7788\n",
      "Epoch 39/100\n",
      "1249/1249 [==============================] - 99s 80ms/step - loss: 0.4887 - accuracy: 0.7837 - val_loss: 0.5436 - val_accuracy: 0.7843ccuracy: 0.7 - ETA: 44s -  - ETA: 2s - loss: 0.492\n",
      "Epoch 40/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4875 - accuracy: 0.7842 - val_loss: 0.6231 - val_accuracy: 0.7608 loss - ETA: 7s - l - ETA: 6s - loss: 0.4926 - accu - E\n",
      "Epoch 41/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4883 - accuracy: 0.7843 - val_loss: 0.5414 - val_accuracy: 0.7834\n",
      "Epoch 42/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4878 - accuracy: 0.7841 - val_loss: 0.7660 - val_accuracy: 0.7740\n",
      "Epoch 43/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4876 - accuracy: 0.7843 - val_loss: 0.7030 - val_accuracy: 0.7850\n",
      "Epoch 44/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4887 - accuracy: 0.7832 - val_loss: 0.3957 - val_accuracy: 0.7803\n",
      "Epoch 45/100\n",
      "1249/1249 [==============================] - 98s 79ms/step - loss: 0.4869 - accuracy: 0.7845 - val_loss: 0.3930 - val_accuracy: 0.7770 - loss: - ETA: 31s - loss: 0.4896 - accuracy:  - ETA: 31s - loss: 0. - ETA: 29s - loss: 0. - ETA: 28s - lo - ETA: 1s - l\n",
      "Epoch 46/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4872 - accuracy: 0.7852 - val_loss: 0.5887 - val_accuracy: 0.788491\n",
      "Epoch 47/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4883 - accuracy: 0.7840 - val_loss: 0.4168 - val_accuracy: 0.7874curacy - ETA: 1:20 - loss: 0.4469 - accuracy:  - E - ETA: 1: - ETA: 1:13 - loss: 0.4695 - ac - ETA: 1:12 - l - ETA: 1:11 - - ETA: 1: - ETA:  - ETA: 1:03 - loss: 0.464  - ETA: 0s - loss: 0.4878 - accuracy: 0. - ETA: 0s - loss: 0.4879 - accuracy: \n",
      "Epoch 48/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4873 - accuracy: 0.7846 - val_loss: 0.7538 - val_accuracy: 0.7891A: 53s - loss: 0.4794 -  - ETA: 0s - loss: 0.4871 - accuracy: 0.78\n",
      "Epoch 49/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4872 - accuracy: 0.7847 - val_loss: 0.3773 - val_accuracy: 0.7899s: 0.4893 - accuracy:  - ETA: 1s - loss:\n",
      "Epoch 50/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4875 - accuracy: 0.7841 - val_loss: 0.0638 - val_accuracy: 0.7822\n",
      "Epoch 51/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4878 - accuracy: 0.7837 - val_loss: 0.2246 - val_accuracy: 0.7710\n",
      "Epoch 52/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4872 - accuracy: 0.7855 - val_loss: 0.5202 - val_accuracy: 0.7290\n",
      "Epoch 53/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4872 - accuracy: 0.7845 - val_loss: 0.3681 - val_accuracy: 0.7713\n",
      "Epoch 54/100\n",
      "1249/1249 [==============================] - 102s 82ms/step - loss: 0.4876 - accuracy: 0.7839 - val_loss: 0.5298 - val_accuracy: 0.7392\n",
      "Epoch 55/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4878 - accuracy: 0.7837 - val_loss: 0.3949 - val_accuracy: 0.7732\n",
      "Epoch 56/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4863 - accuracy: 0.7853 - val_loss: 0.4846 - val_accuracy: 0.7800\n",
      "Epoch 57/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4864 - accuracy: 0.7859 - val_loss: 0.5454 - val_accuracy: 0.7691\n",
      "Epoch 58/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4871 - accuracy: 0.7851 - val_loss: 0.5751 - val_accuracy: 0.7786\n",
      "Epoch 59/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4873 - accuracy: 0.7848 - val_loss: 0.5791 - val_accuracy: 0.7702\n",
      "Epoch 60/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4888 - accuracy: 0.7837 - val_loss: 0.5998 - val_accuracy: 0.7804\n",
      "Epoch 61/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4884 - accuracy: 0.7844 - val_loss: 0.2357 - val_accuracy: 0.7684\n",
      "Epoch 62/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4892 - accuracy: 0.7835 - val_loss: 0.4690 - val_accuracy: 0.7646\n",
      "Epoch 63/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4885 - accuracy: 0.7830 - val_loss: 0.7290 - val_accuracy: 0.7577\n",
      "Epoch 64/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4867 - accuracy: 0.7839 - val_loss: 0.3427 - val_accuracy: 0.7662\n",
      "Epoch 65/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4873 - accuracy: 0.7856 - val_loss: 0.4556 - val_accuracy: 0.7760\n",
      "Epoch 66/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4867 - accuracy: 0.7846 - val_loss: 0.1840 - val_accuracy: 0.7460 loss: 0.4904 - acc - ETA: 0s - loss: 0.4890 \n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4884 - accuracy: 0.7832 - val_loss: 0.2738 - val_accuracy: 0.7473\n",
      "Epoch 68/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4871 - accuracy: 0.7851 - val_loss: 0.2057 - val_accuracy: 0.7562\n",
      "Epoch 69/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4866 - accuracy: 0.7846 - val_loss: 0.5393 - val_accuracy: 0.7670\n",
      "Epoch 70/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4875 - accuracy: 0.7844 - val_loss: 0.5752 - val_accuracy: 0.7642\n",
      "Epoch 71/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4871 - accuracy: 0.7849 - val_loss: 0.5459 - val_accuracy: 0.7550\n",
      "Epoch 72/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4877 - accuracy: 0.7841 - val_loss: 0.4447 - val_accuracy: 0.7492\n",
      "Epoch 73/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4877 - accuracy: 0.7844 - val_loss: 0.7121 - val_accuracy: 0.7519\n",
      "Epoch 74/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4891 - accuracy: 0.7838 - val_loss: 0.4381 - val_accuracy: 0.7667\n",
      "Epoch 75/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4873 - accuracy: 0.7847 - val_loss: 0.6517 - val_accuracy: 0.7861\n",
      "Epoch 76/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4886 - accuracy: 0.7846 - val_loss: 0.4908 - val_accuracy: 0.7717\n",
      "Epoch 77/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4866 - accuracy: 0.7858 - val_loss: 0.4194 - val_accuracy: 0.7795\n",
      "Epoch 78/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4869 - accuracy: 0.7839 - val_loss: 0.7528 - val_accuracy: 0.7648\n",
      "Epoch 79/100\n",
      "1249/1249 [==============================] - 102s 81ms/step - loss: 0.4861 - accuracy: 0.7848 - val_loss: 0.8048 - val_accuracy: 0.7785\n",
      "Epoch 80/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4883 - accuracy: 0.7842 - val_loss: 0.4143 - val_accuracy: 0.7861\n",
      "Epoch 81/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4867 - accuracy: 0.7846 - val_loss: 0.2781 - val_accuracy: 0.7819\n",
      "Epoch 82/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4871 - accuracy: 0.7860 - val_loss: 0.3509 - val_accuracy: 0.7866\n",
      "Epoch 83/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4876 - accuracy: 0.7843 - val_loss: 0.6945 - val_accuracy: 0.7783\n",
      "Epoch 84/100\n",
      "1249/1249 [==============================] - 102s 81ms/step - loss: 0.4874 - accuracy: 0.7849 - val_loss: 0.6182 - val_accuracy: 0.7624\n",
      "Epoch 85/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4870 - accuracy: 0.7844 - val_loss: 0.7735 - val_accuracy: 0.7818\n",
      "Epoch 86/100\n",
      "1249/1249 [==============================] - 101s 81ms/step - loss: 0.4874 - accuracy: 0.7844 - val_loss: 0.8151 - val_accuracy: 0.7907\n",
      "Epoch 87/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4863 - accuracy: 0.7856 - val_loss: 0.6500 - val_accuracy: 0.7906\n",
      "Epoch 88/100\n",
      "1249/1249 [==============================] - 99s 80ms/step - loss: 0.4874 - accuracy: 0.7854 - val_loss: 0.1253 - val_accuracy: 0.7869\n",
      "Epoch 89/100\n",
      "1249/1249 [==============================] - 99s 80ms/step - loss: 0.4860 - accuracy: 0.7852 - val_loss: 0.2863 - val_accuracy: 0.7858\n",
      "Epoch 90/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4843 - accuracy: 0.7866 - val_loss: 0.3309 - val_accuracy: 0.7853\n",
      "Epoch 91/100\n",
      "1249/1249 [==============================] - 98s 78ms/step - loss: 0.4868 - accuracy: 0.7846 - val_loss: 0.8460 - val_accuracy: 0.7842\n",
      "Epoch 92/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4856 - accuracy: 0.7856 - val_loss: 0.4030 - val_accuracy: 0.7798 accura\n",
      "Epoch 93/100\n",
      "1249/1249 [==============================] - 99s 80ms/step - loss: 0.4860 - accuracy: 0.7844 - val_loss: 0.5737 - val_accuracy: 0.7797: 0.4727  - ETA: 41s - - ETA: 0s - los\n",
      "Epoch 94/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4875 - accuracy: 0.7842 - val_loss: 0.4295 - val_accuracy: 0.7843\n",
      "Epoch 95/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4848 - accuracy: 0.7857 - val_loss: 0.3775 - val_accuracy: 0.7882\n",
      "Epoch 96/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4880 - accuracy: 0.7843 - val_loss: 0.2502 - val_accuracy: 0.7756\n",
      "Epoch 97/100\n",
      "1249/1249 [==============================] - 100s 80ms/step - loss: 0.4881 - accuracy: 0.7853 - val_loss: 0.6157 - val_accuracy: 0.77544\n",
      "Epoch 98/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4864 - accuracy: 0.7857 - val_loss: 0.4668 - val_accuracy: 0.7767accura\n",
      "Epoch 99/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4882 - accuracy: 0.7848 - val_loss: 0.6483 - val_accuracy: 0.7833\n",
      "Epoch 100/100\n",
      "1249/1249 [==============================] - 99s 79ms/step - loss: 0.4861 - accuracy: 0.7853 - val_loss: 0.4779 - val_accuracy: 0.7901\n",
      "Prediction on test data\n",
      "best epoch:  002\n",
      "Counting predicted:  Counter({1: 19318, 0: 1245})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7634\n",
      "Confusion matrix:\n",
      "[[  731  4351]\n",
      " [  514 14967]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.14      0.23      5082\n",
      "           1       0.77      0.97      0.86     15481\n",
      "\n",
      "    accuracy                           0.76     20563\n",
      "   macro avg       0.68      0.56      0.55     20563\n",
      "weighted avg       0.73      0.76      0.70     20563\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.710776\n",
      "Fold: 3\n",
      "Training\n",
      "Epoch 1/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.5006 - accuracy: 0.7784 - val_loss: 0.3548 - val_accuracy: 0.7658\n",
      "Epoch 2/100\n",
      "1246/1246 [==============================] - 97s 78ms/step - loss: 0.4998 - accuracy: 0.7786 - val_loss: 0.1263 - val_accuracy: 0.7778\n",
      "Epoch 3/100\n",
      "1246/1246 [==============================] - 96s 77ms/step - loss: 0.4992 - accuracy: 0.7791 - val_loss: 0.4335 - val_accuracy: 0.7810\n",
      "Epoch 4/100\n",
      "1246/1246 [==============================] - 96s 77ms/step - loss: 0.4983 - accuracy: 0.7779 - val_loss: 0.0407 - val_accuracy: 0.7860\n",
      "Epoch 5/100\n",
      "1246/1246 [==============================] - 96s 77ms/step - loss: 0.4984 - accuracy: 0.7778 - val_loss: 0.3840 - val_accuracy: 0.7810\n",
      "Epoch 6/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4959 - accuracy: 0.7795 - val_loss: 0.1169 - val_accuracy: 0.7808\n",
      "Epoch 7/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4962 - accuracy: 0.7796 - val_loss: 0.2121 - val_accuracy: 0.7811\n",
      "Epoch 8/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4976 - accuracy: 0.7797 - val_loss: 0.1723 - val_accuracy: 0.7722\n",
      "Epoch 9/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4969 - accuracy: 0.7787 - val_loss: 0.5899 - val_accuracy: 0.7770\n",
      "Epoch 10/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4953 - accuracy: 0.7784 - val_loss: 0.5655 - val_accuracy: 0.7736\n",
      "Epoch 11/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4957 - accuracy: 0.7780 - val_loss: 0.6477 - val_accuracy: 0.7741\n",
      "Epoch 12/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4948 - accuracy: 0.7786 - val_loss: 0.8338 - val_accuracy: 0.7633\n",
      "Epoch 13/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4965 - accuracy: 0.7788 - val_loss: 0.6484 - val_accuracy: 0.7645\n",
      "Epoch 14/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4952 - accuracy: 0.7788 - val_loss: 0.6092 - val_accuracy: 0.7698\n",
      "Epoch 15/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4941 - accuracy: 0.7789 - val_loss: 0.6010 - val_accuracy: 0.7702\n",
      "Epoch 16/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4939 - accuracy: 0.7795 - val_loss: 0.7110 - val_accuracy: 0.7751\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4956 - accuracy: 0.7792 - val_loss: 0.5362 - val_accuracy: 0.7748\n",
      "Epoch 18/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4930 - accuracy: 0.7802 - val_loss: 0.6842 - val_accuracy: 0.7786: 22s - loss: 0.495 - ETA: 21s - loss: 0.4969 - accur - ETA: 20s - loss: 0.4975 - accuracy: 0.77 - ETA: 20s - loss: 0.4973 -  - ETA: 18s - loss: 0.4970  - ETA: 14s - loss: 0.4 - ETA: 12s - loss: 0.4983 - accuracy - - ETA: 0s - loss:\n",
      "Epoch 19/100\n",
      "1246/1246 [==============================] - 98s 78ms/step - loss: 0.4941 - accuracy: 0.7784 - val_loss: 0.1659 - val_accuracy: 0.7779\n",
      "Epoch 20/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4941 - accuracy: 0.7788 - val_loss: 0.6035 - val_accuracy: 0.7825\n",
      "Epoch 21/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4938 - accuracy: 0.7804 - val_loss: 0.4106 - val_accuracy: 0.7839\n",
      "Epoch 22/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4936 - accuracy: 0.7802 - val_loss: 0.3168 - val_accuracy: 0.7743\n",
      "Epoch 23/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4940 - accuracy: 0.7794 - val_loss: 0.4494 - val_accuracy: 0.7822\n",
      "Epoch 24/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4938 - accuracy: 0.7799 - val_loss: 0.6915 - val_accuracy: 0.7802\n",
      "Epoch 25/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4954 - accuracy: 0.7798 - val_loss: 0.4271 - val_accuracy: 0.7829\n",
      "Epoch 26/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4934 - accuracy: 0.7799 - val_loss: 0.5393 - val_accuracy: 0.7803\n",
      "Epoch 27/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4941 - accuracy: 0.7796 - val_loss: 0.4901 - val_accuracy: 0.7832\n",
      "Epoch 28/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4930 - accuracy: 0.7795 - val_loss: 0.5717 - val_accuracy: 0.7806ETA: 3s - loss: 0.4911 - accuracy:  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.4\n",
      "Epoch 29/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4919 - accuracy: 0.7815 - val_loss: 0.4732 - val_accuracy: 0.7807 accuracy: 0.\n",
      "Epoch 30/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4923 - accuracy: 0.7819 - val_loss: 0.5621 - val_accuracy: 0.7785\n",
      "Epoch 31/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4917 - accuracy: 0.7805 - val_loss: 0.3245 - val_accuracy: 0.7843loss: 0.4881 - accuracy: 0. - ETA: 11s - loss: 0.4966 - ac  - E\n",
      "Epoch 32/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4923 - accuracy: 0.7809 - val_loss: 0.4056 - val_accuracy: 0.7799- loss: 0.4920  - ETA: 0s - loss: 0.4924 - accuracy\n",
      "Epoch 33/100\n",
      "1246/1246 [==============================] - 100s 81ms/step - loss: 0.4929 - accuracy: 0.7803 - val_loss: 0.6050 - val_accuracy: 0.7748.4882 - accuracy:  - ET - E - ETA: 2s - loss: 0\n",
      "Epoch 34/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4929 - accuracy: 0.7795 - val_loss: 0.4001 - val_accuracy: 0.7713\n",
      "Epoch 35/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4916 - accuracy: 0.7810 - val_loss: 0.3141 - val_accuracy: 0.7684.4917 - \n",
      "Epoch 36/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4916 - accuracy: 0.7807 - val_loss: 0.6517 - val_accuracy: 0.7791\n",
      "Epoch 37/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4936 - accuracy: 0.7804 - val_loss: 0.7245 - val_accuracy: 0.7766\n",
      "Epoch 38/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4919 - accuracy: 0.7809 - val_loss: 0.5548 - val_accuracy: 0.7727\n",
      "Epoch 39/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4918 - accuracy: 0.7815 - val_loss: 0.4395 - val_accuracy: 0.77034845 - accuracy: 0.7 - ETA: 34s - loss: 0.4848 - accuracy - ETA: 33s - loss: 0.4867 - accur - ETA: 33s - loss: 0.4888 - accuracy - ETA: 32s  - ETA: 30s - loss: 0.4889  - ETA: 28s - loss: 0.4912 - accuracy: 0 - ETA: 28s - loss: 0.4915 - accuracy: 0. - ETA: 27s - loss: 0.49\n",
      "Epoch 40/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4921 - accuracy: 0.7815 - val_loss: 0.6072 - val_accuracy: 0.7659\n",
      "Epoch 41/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4907 - accuracy: 0.7811 - val_loss: 0.6869 - val_accuracy: 0.7792\n",
      "Epoch 42/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4921 - accuracy: 0.7806 - val_loss: 0.5695 - val_accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4908 - accuracy: 0.7815 - val_loss: 0.5602 - val_accuracy: 0.7787\n",
      "Epoch 44/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4916 - accuracy: 0.7812 - val_loss: 0.4206 - val_accuracy: 0.7549\n",
      "Epoch 45/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4896 - accuracy: 0.7823 - val_loss: 0.3422 - val_accuracy: 0.7529\n",
      "Epoch 46/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4901 - accuracy: 0.7815 - val_loss: 0.3065 - val_accuracy: 0.7540\n",
      "Epoch 47/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4905 - accuracy: 0.7817 - val_loss: 1.0947 - val_accuracy: 0.7403 loss: 0.4903 - ac\n",
      "Epoch 48/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4918 - accuracy: 0.7800 - val_loss: 0.8469 - val_accuracy: 0.7403oss: 0.4909 - accura - ETA: 0s - loss: 0.4913 - accu - ETA: 0s - loss: 0.4920 - accuracy: 0.77\n",
      "Epoch 49/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4909 - accuracy: 0.7814 - val_loss: 0.3560 - val_accuracy: 0.7390\n",
      "Epoch 50/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4916 - accuracy: 0.7792 - val_loss: 0.4801 - val_accuracy: 0.7283\n",
      "Epoch 51/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4910 - accuracy: 0.7809 - val_loss: 0.5200 - val_accuracy: 0.7332ra - ETA: 34s -  - ETA:  - ETA: 0s - loss: 0.489 - ETA: 0s - loss: 0.4910 - accuracy: 0.\n",
      "Epoch 52/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4922 - accuracy: 0.7812 - val_loss: 0.7729 - val_accuracy: 0.7142 loss: 0.4912 - ac\n",
      "Epoch 53/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4923 - accuracy: 0.7799 - val_loss: 0.3564 - val_accuracy: 0.7234\n",
      "Epoch 54/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4910 - accuracy: 0.7803 - val_loss: 0.4599 - val_accuracy: 0.7581\n",
      "Epoch 55/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4907 - accuracy: 0.7810 - val_loss: 0.3980 - val_accuracy: 0.7535\n",
      "Epoch 56/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4905 - accuracy: 0.7818 - val_loss: 0.5330 - val_accuracy: 0.7266\n",
      "Epoch 57/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4919 - accuracy: 0.7794 - val_loss: 0.3823 - val_accuracy: 0.7213\n",
      "Epoch 58/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4897 - accuracy: 0.7811 - val_loss: 0.3712 - val_accuracy: 0.7272\n",
      "Epoch 59/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4906 - accuracy: 0.7822 - val_loss: 0.5355 - val_accuracy: 0.7262 - l\n",
      "Epoch 60/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4898 - accuracy: 0.7809 - val_loss: 0.4700 - val_accuracy: 0.7488racy\n",
      "Epoch 61/100\n",
      "1246/1246 [==============================] - 97s 78ms/step - loss: 0.4904 - accuracy: 0.7820 - val_loss: 0.5544 - val_accuracy: 0.7483\n",
      "Epoch 62/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4903 - accuracy: 0.7809 - val_loss: 0.6226 - val_accuracy: 0.7624\n",
      "Epoch 63/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4904 - accuracy: 0.7813 - val_loss: 0.4039 - val_accuracy: 0.7561\n",
      "Epoch 64/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4908 - accuracy: 0.7805 - val_loss: 0.2352 - val_accuracy: 0.7532\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4907 - accuracy: 0.7814 - val_loss: 0.5134 - val_accuracy: 0.7522\n",
      "Epoch 66/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4905 - accuracy: 0.7812 - val_loss: 0.7663 - val_accuracy: 0.7213\n",
      "Epoch 67/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4903 - accuracy: 0.7806 - val_loss: 0.6406 - val_accuracy: 0.7374\n",
      "Epoch 68/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4916 - accuracy: 0.7811 - val_loss: 0.4843 - val_accuracy: 0.7615\n",
      "Epoch 69/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4907 - accuracy: 0.7812 - val_loss: 0.7512 - val_accuracy: 0.7379\n",
      "Epoch 70/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4906 - accuracy: 0.7806 - val_loss: 0.6360 - val_accuracy: 0.7489\n",
      "Epoch 71/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4884 - accuracy: 0.7824 - val_loss: 0.5747 - val_accuracy: 0.7588 loss: 0.4876 - ac\n",
      "Epoch 72/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4894 - accuracy: 0.7809 - val_loss: 0.6239 - val_accuracy: 0.7704 - ETA: 1s -\n",
      "Epoch 73/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4893 - accuracy: 0.7822 - val_loss: 0.6197 - val_accuracy: 0.7646 - loss: 0.4887 \n",
      "Epoch 74/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4906 - accuracy: 0.7803 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
      "Epoch 75/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4901 - accuracy: 0.7816 - val_loss: 0.4629 - val_accuracy: 0.7769\n",
      "Epoch 76/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4892 - accuracy: 0.7815 - val_loss: 0.3626 - val_accuracy: 0.7722\n",
      "Epoch 77/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4885 - accuracy: 0.7815 - val_loss: 0.3333 - val_accuracy: 0.7765\n",
      "Epoch 78/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4911 - accuracy: 0.7810 - val_loss: 0.5599 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4905 - accuracy: 0.7804 - val_loss: 0.3825 - val_accuracy: 0.7749 - ETA: 7s - loss: 0.4976 - accuracy:  - - ETA: \n",
      "Epoch 80/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4900 - accuracy: 0.7805 - val_loss: 0.4490 - val_accuracy: 0.7786\n",
      "Epoch 81/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4926 - accuracy: 0.7794 - val_loss: 0.4649 - val_accuracy: 0.7810\n",
      "Epoch 82/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4909 - accuracy: 0.7815 - val_loss: 0.7940 - val_accuracy: 0.7811s - loss: 0.4966 - accuracy: - ETA: 11s - los\n",
      "Epoch 83/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4908 - accuracy: 0.7814 - val_loss: 0.8257 - val_accuracy: 0.7813\n",
      "Epoch 84/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4909 - accuracy: 0.7811 - val_loss: 0.6634 - val_accuracy: 0.7855\n",
      "Epoch 85/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4912 - accuracy: 0.7823 - val_loss: 0.6928 - val_accuracy: 0.7827\n",
      "Epoch 86/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4902 - accuracy: 0.7814 - val_loss: 0.4431 - val_accuracy: 0.7832\n",
      "Epoch 87/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4889 - accuracy: 0.7813 - val_loss: 0.5950 - val_accuracy: 0.7802\n",
      "Epoch 88/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4910 - accuracy: 0.7809 - val_loss: 0.9318 - val_accuracy: 0.7810\n",
      "Epoch 89/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4908 - accuracy: 0.7811 - val_loss: 0.7638 - val_accuracy: 0.7823\n",
      "Epoch 90/100\n",
      "1246/1246 [==============================] - 99s 79ms/step - loss: 0.4910 - accuracy: 0.7817 - val_loss: 0.5258 - val_accuracy: 0.7809\n",
      "Epoch 91/100\n",
      "1246/1246 [==============================] - 97s 78ms/step - loss: 0.4894 - accuracy: 0.7817 - val_loss: 0.4641 - val_accuracy: 0.7821\n",
      "Epoch 92/100\n",
      "1246/1246 [==============================] - 100s 80ms/step - loss: 0.4878 - accuracy: 0.7831 - val_loss: 0.6087 - val_accuracy: 0.7803\n",
      "Epoch 93/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4896 - accuracy: 0.7826 - val_loss: 0.5554 - val_accuracy: 0.7803\n",
      "Epoch 94/100\n",
      "1246/1246 [==============================] - 96s 77ms/step - loss: 0.4898 - accuracy: 0.7817 - val_loss: 0.4801 - val_accuracy: 0.7824 loss: 0.4907 - accuracy - ETA: 0s - loss: 0.4899 \n",
      "Epoch 95/100\n",
      "1246/1246 [==============================] - 96s 77ms/step - loss: 0.4910 - accuracy: 0.7814 - val_loss: 0.4890 - val_accuracy: 0.7800\n",
      "Epoch 96/100\n",
      "1246/1246 [==============================] - 98s 78ms/step - loss: 0.4893 - accuracy: 0.7833 - val_loss: 0.5630 - val_accuracy: 0.7809loss:  - ETA: 36s -  - ETA - ETA: 31s - lo - ETA: 28s - loss: 0.4883 - ac - ETA: 27 - ETA: 24s - loss: 0.4915 - a - ETA: 23s - loss: 0.4926 - accuracy - E - ETA: 6s - ETA: 5s - loss: 0.4 - - ETA: 1s - los\n",
      "Epoch 97/100\n",
      "1246/1246 [==============================] - 97s 78ms/step - loss: 0.4904 - accuracy: 0.7815 - val_loss: 0.9676 - val_accuracy: 0.7738\n",
      "Epoch 98/100\n",
      "1246/1246 [==============================] - 97s 78ms/step - loss: 0.4903 - accuracy: 0.7811 - val_loss: 0.4684 - val_accuracy: 0.7762ur - ETA: 27s - loss: 0.4911 - accur - ETA: 26s - loss:  - - ETA: 21s - loss - ETA: 1\n",
      "Epoch 99/100\n",
      "1246/1246 [==============================] - 98s 79ms/step - loss: 0.4889 - accuracy: 0.7822 - val_loss: 0.4141 - val_accuracy: 0.7708\n",
      "Epoch 100/100\n",
      "1246/1246 [==============================] - 99s 80ms/step - loss: 0.4904 - accuracy: 0.7813 - val_loss: 0.5435 - val_accuracy: 0.7652\n",
      "Prediction on test data\n",
      "best epoch:  004\n",
      "Counting predicted:  Counter({1: 19622, 0: 1570})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7813\n",
      "Confusion matrix:\n",
      "[[  983  4047]\n",
      " [  587 15575]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.20      0.30      5030\n",
      "           1       0.79      0.96      0.87     16162\n",
      "\n",
      "    accuracy                           0.78     21192\n",
      "   macro avg       0.71      0.58      0.58     21192\n",
      "weighted avg       0.75      0.78      0.73     21192\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.684424\n",
      "Fold: 4\n",
      "Training\n",
      "Epoch 1/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4975 - accuracy: 0.7780 - val_loss: 0.5269 - val_accuracy: 0.7609\n",
      "Epoch 2/100\n",
      "1218/1218 [==============================] - 99s 81ms/step - loss: 0.4957 - accuracy: 0.7797 - val_loss: 0.6486 - val_accuracy: 0.7665\n",
      "Epoch 3/100\n",
      "1218/1218 [==============================] - 99s 82ms/step - loss: 0.4964 - accuracy: 0.7799 - val_loss: 0.5395 - val_accuracy: 0.7736\n",
      "Epoch 4/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4953 - accuracy: 0.7801 - val_loss: 0.6777 - val_accuracy: 0.7712\n",
      "Epoch 5/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4966 - accuracy: 0.7789 - val_loss: 0.3956 - val_accuracy: 0.7738\n",
      "Epoch 6/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4966 - accuracy: 0.7788 - val_loss: 0.4463 - val_accuracy: 0.7689\n",
      "Epoch 7/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4955 - accuracy: 0.7793 - val_loss: 0.4370 - val_accuracy: 0.7679\n",
      "Epoch 8/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4946 - accuracy: 0.7798 - val_loss: 0.7111 - val_accuracy: 0.7675\n",
      "Epoch 9/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4944 - accuracy: 0.7806 - val_loss: 1.9267 - val_accuracy: 0.7670\n",
      "Epoch 10/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4964 - accuracy: 0.7799 - val_loss: 0.1871 - val_accuracy: 0.7664\n",
      "Epoch 11/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4955 - accuracy: 0.7789 - val_loss: 0.2341 - val_accuracy: 0.7620\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4947 - accuracy: 0.7795 - val_loss: 0.6757 - val_accuracy: 0.7625\n",
      "Epoch 13/100\n",
      "1218/1218 [==============================] - 99s 82ms/step - loss: 0.4952 - accuracy: 0.7791 - val_loss: 0.4634 - val_accuracy: 0.7652\n",
      "Epoch 14/100\n",
      "1218/1218 [==============================] - 99s 82ms/step - loss: 0.4966 - accuracy: 0.7782 - val_loss: 0.4350 - val_accuracy: 0.7612\n",
      "Epoch 15/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4959 - accuracy: 0.7794 - val_loss: 0.6221 - val_accuracy: 0.7625\n",
      "Epoch 16/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4935 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7663\n",
      "Epoch 17/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4956 - accuracy: 0.7794 - val_loss: 0.7103 - val_accuracy: 0.7587\n",
      "Epoch 18/100\n",
      "1218/1218 [==============================] - 99s 82ms/step - loss: 0.4953 - accuracy: 0.7799 - val_loss: 0.7482 - val_accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "1218/1218 [==============================] - 99s 81ms/step - loss: 0.4958 - accuracy: 0.7796 - val_loss: 0.4282 - val_accuracy: 0.7632\n",
      "Epoch 20/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4947 - accuracy: 0.7796 - val_loss: 0.5042 - val_accuracy: 0.7626\n",
      "Epoch 21/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4937 - accuracy: 0.7804 - val_loss: 0.5794 - val_accuracy: 0.7670\n",
      "Epoch 22/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4939 - accuracy: 0.7803 - val_loss: 0.6494 - val_accuracy: 0.7626\n",
      "Epoch 23/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4941 - accuracy: 0.7803 - val_loss: 0.6194 - val_accuracy: 0.7649\n",
      "Epoch 24/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4939 - accuracy: 0.7802 - val_loss: 0.5080 - val_accuracy: 0.7673: 0.4944 - ac\n",
      "Epoch 25/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4958 - accuracy: 0.7797 - val_loss: 0.6357 - val_accuracy: 0.7694\n",
      "Epoch 26/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4940 - accuracy: 0.7800 - val_loss: 0.3491 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4939 - accuracy: 0.7796 - val_loss: 0.5515 - val_accuracy: 0.7698\n",
      "Epoch 28/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4940 - accuracy: 0.7804 - val_loss: 0.5804 - val_accuracy: 0.7666\n",
      "Epoch 29/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4938 - accuracy: 0.7795 - val_loss: 0.3464 - val_accuracy: 0.7694\n",
      "Epoch 30/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4926 - accuracy: 0.7813 - val_loss: 0.6240 - val_accuracy: 0.7657\n",
      "Epoch 31/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4921 - accuracy: 0.7815 - val_loss: 0.6322 - val_accuracy: 0.7686\n",
      "Epoch 32/100\n",
      "1218/1218 [==============================] - 102s 84ms/step - loss: 0.4934 - accuracy: 0.7799 - val_loss: 0.6911 - val_accuracy: 0.7639\n",
      "Epoch 33/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4931 - accuracy: 0.7805 - val_loss: 0.7199 - val_accuracy: 0.7654\n",
      "Epoch 34/100\n",
      "1218/1218 [==============================] - 102s 83ms/step - loss: 0.4946 - accuracy: 0.7798 - val_loss: 0.7427 - val_accuracy: 0.7655\n",
      "Epoch 35/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4932 - accuracy: 0.7810 - val_loss: 0.7194 - val_accuracy: 0.7547\n",
      "Epoch 36/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4925 - accuracy: 0.7800 - val_loss: 0.8214 - val_accuracy: 0.7620\n",
      "Epoch 37/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4916 - accuracy: 0.7814 - val_loss: 0.6296 - val_accuracy: 0.7636\n",
      "Epoch 38/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4905 - accuracy: 0.7824 - val_loss: 0.4245 - val_accuracy: 0.7636\n",
      "Epoch 39/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4938 - accuracy: 0.7800 - val_loss: 0.8332 - val_accuracy: 0.7563\n",
      "Epoch 40/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4917 - accuracy: 0.7817 - val_loss: 0.7377 - val_accuracy: 0.7612\n",
      "Epoch 41/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4920 - accuracy: 0.7816 - val_loss: 0.7138 - val_accuracy: 0.7566\n",
      "Epoch 42/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4921 - accuracy: 0.7813 - val_loss: 0.2677 - val_accuracy: 0.7549\n",
      "Epoch 43/100\n",
      "1218/1218 [==============================] - 102s 83ms/step - loss: 0.4923 - accuracy: 0.7807 - val_loss: 0.3747 - val_accuracy: 0.7589\n",
      "Epoch 44/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4930 - accuracy: 0.7801 - val_loss: 0.6555 - val_accuracy: 0.7532ccuracy: \n",
      "Epoch 45/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4914 - accuracy: 0.7806 - val_loss: 0.7471 - val_accuracy: 0.7604\n",
      "Epoch 46/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4920 - accuracy: 0.7806 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4931 - accuracy: 0.7807 - val_loss: 0.7745 - val_accuracy: 0.7602\n",
      "Epoch 48/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4917 - accuracy: 0.7819 - val_loss: 0.5697 - val_accuracy: 0.7535\n",
      "Epoch 49/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4910 - accuracy: 0.7816 - val_loss: 0.4604 - val_accuracy: 0.7471\n",
      "Epoch 50/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4913 - accuracy: 0.7817 - val_loss: 0.5300 - val_accuracy: 0.7494\n",
      "Epoch 51/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4906 - accuracy: 0.7812 - val_loss: 0.5471 - val_accuracy: 0.7555\n",
      "Epoch 52/100\n",
      "1218/1218 [==============================] - 102s 84ms/step - loss: 0.4919 - accuracy: 0.7804 - val_loss: 0.3708 - val_accuracy: 0.7506\n",
      "Epoch 53/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4916 - accuracy: 0.7817 - val_loss: 0.9140 - val_accuracy: 0.7489 \n",
      "Epoch 54/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4922 - accuracy: 0.7808 - val_loss: 0.3632 - val_accuracy: 0.7534\n",
      "Epoch 55/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4924 - accuracy: 0.7809 - val_loss: 0.3567 - val_accuracy: 0.7573 0.4980 - accuracy:  - ETA: 7s - ETA: \n",
      "Epoch 56/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4914 - accuracy: 0.7813 - val_loss: 0.4652 - val_accuracy: 0.7444\n",
      "Epoch 57/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4909 - accuracy: 0.7812 - val_loss: 0.1068 - val_accuracy: 0.7484\n",
      "Epoch 58/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4926 - accuracy: 0.7805 - val_loss: 0.5716 - val_accuracy: 0.7485\n",
      "Epoch 59/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4930 - accuracy: 0.7806 - val_loss: 0.5581 - val_accuracy: 0.7612\n",
      "Epoch 60/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4910 - accuracy: 0.7808 - val_loss: 0.3526 - val_accuracy: 0.7639\n",
      "Epoch 61/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4939 - accuracy: 0.7803 - val_loss: 0.1547 - val_accuracy: 0.7505\n",
      "Epoch 62/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4917 - accuracy: 0.7809 - val_loss: 0.1814 - val_accuracy: 0.7562\n",
      "Epoch 63/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4903 - accuracy: 0.7820 - val_loss: 0.7542 - val_accuracy: 0.7451\n",
      "Epoch 64/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4910 - accuracy: 0.7816 - val_loss: 0.4450 - val_accuracy: 0.7553\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4929 - accuracy: 0.7805 - val_loss: 0.5231 - val_accuracy: 0.7646\n",
      "Epoch 66/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4910 - accuracy: 0.7819 - val_loss: 0.5721 - val_accuracy: 0.7649\n",
      "Epoch 67/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4912 - accuracy: 0.7819 - val_loss: 0.2592 - val_accuracy: 0.7660\n",
      "Epoch 68/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4918 - accuracy: 0.7809 - val_loss: 0.4174 - val_accuracy: 0.7702\n",
      "Epoch 69/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4920 - accuracy: 0.7804 - val_loss: 0.7407 - val_accuracy: 0.7666\n",
      "Epoch 70/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4905 - accuracy: 0.7821 - val_loss: 0.3633 - val_accuracy: 0.7678\n",
      "Epoch 71/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4911 - accuracy: 0.7811 - val_loss: 0.3169 - val_accuracy: 0.7663\n",
      "Epoch 72/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4920 - accuracy: 0.7815 - val_loss: 0.4461 - val_accuracy: 0.7598\n",
      "Epoch 73/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4919 - accuracy: 0.7808 - val_loss: 0.8191 - val_accuracy: 0.7634\n",
      "Epoch 74/100\n",
      "1218/1218 [==============================] - 100s 83ms/step - loss: 0.4913 - accuracy: 0.7811 - val_loss: 0.4955 - val_accuracy: 0.7628\n",
      "Epoch 75/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4899 - accuracy: 0.7813 - val_loss: 0.4409 - val_accuracy: 0.7658\n",
      "Epoch 76/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4920 - accuracy: 0.7806 - val_loss: 0.4878 - val_accuracy: 0.7655\n",
      "Epoch 77/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4912 - accuracy: 0.7806 - val_loss: 0.3164 - val_accuracy: 0.7619\n",
      "Epoch 78/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4909 - accuracy: 0.7821 - val_loss: 0.5431 - val_accuracy: 0.7627\n",
      "Epoch 79/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4905 - accuracy: 0.7817 - val_loss: 0.4024 - val_accuracy: 0.7644\n",
      "Epoch 80/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4912 - accuracy: 0.7809 - val_loss: 0.5416 - val_accuracy: 0.7644\n",
      "Epoch 81/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4904 - accuracy: 0.7813 - val_loss: 0.9164 - val_accuracy: 0.7664\n",
      "Epoch 82/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4923 - accuracy: 0.7810 - val_loss: 0.6624 - val_accuracy: 0.7628\n",
      "Epoch 83/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4908 - accuracy: 0.7813 - val_loss: 0.2979 - val_accuracy: 0.7640\n",
      "Epoch 84/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4916 - accuracy: 0.7804 - val_loss: 0.2572 - val_accuracy: 0.7668\n",
      "Epoch 85/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4913 - accuracy: 0.7818 - val_loss: 0.5431 - val_accuracy: 0.7591\n",
      "Epoch 86/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4903 - accuracy: 0.7815 - val_loss: 0.5782 - val_accuracy: 0.7647\n",
      "Epoch 87/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4919 - accuracy: 0.7805 - val_loss: 0.4789 - val_accuracy: 0.7639\n",
      "Epoch 88/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4916 - accuracy: 0.7816 - val_loss: 0.8534 - val_accuracy: 0.7675\n",
      "Epoch 89/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4906 - accuracy: 0.7820 - val_loss: 0.7799 - val_accuracy: 0.7669\n",
      "Epoch 90/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4891 - accuracy: 0.7826 - val_loss: 0.3353 - val_accuracy: 0.7668\n",
      "Epoch 91/100\n",
      "1218/1218 [==============================] - 102s 84ms/step - loss: 0.4911 - accuracy: 0.7808 - val_loss: 0.2190 - val_accuracy: 0.7642\n",
      "Epoch 92/100\n",
      "1218/1218 [==============================] - 102s 84ms/step - loss: 0.4902 - accuracy: 0.7816 - val_loss: 0.5555 - val_accuracy: 0.7634\n",
      "Epoch 93/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4897 - accuracy: 0.7816 - val_loss: 0.6677 - val_accuracy: 0.7629\n",
      "Epoch 94/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4907 - accuracy: 0.7818 - val_loss: 0.3466 - val_accuracy: 0.7637\n",
      "Epoch 95/100\n",
      "1218/1218 [==============================] - 100s 82ms/step - loss: 0.4904 - accuracy: 0.7813 - val_loss: 0.5530 - val_accuracy: 0.7621\n",
      "Epoch 96/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4901 - accuracy: 0.7823 - val_loss: 0.2575 - val_accuracy: 0.7621\n",
      "Epoch 97/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4930 - accuracy: 0.7799 - val_loss: 0.0385 - val_accuracy: 0.7636\n",
      "Epoch 98/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4916 - accuracy: 0.7818 - val_loss: 0.0429 - val_accuracy: 0.7560\n",
      "Epoch 99/100\n",
      "1218/1218 [==============================] - 102s 84ms/step - loss: 0.4921 - accuracy: 0.7809 - val_loss: 0.5048 - val_accuracy: 0.7609\n",
      "Epoch 100/100\n",
      "1218/1218 [==============================] - 101s 83ms/step - loss: 0.4904 - accuracy: 0.7821 - val_loss: 0.4726 - val_accuracy: 0.7666\n",
      "Prediction on test data\n",
      "best epoch:  005\n",
      "Counting predicted:  Counter({1: 19804, 0: 873})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.8055\n",
      "Confusion matrix:\n",
      "[[  540  3689]\n",
      " [  333 16115]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.13      0.21      4229\n",
      "           1       0.81      0.98      0.89     16448\n",
      "\n",
      "    accuracy                           0.81     20677\n",
      "   macro avg       0.72      0.55      0.55     20677\n",
      "weighted avg       0.77      0.81      0.75     20677\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.684019\n",
      "Fold: 5\n",
      "Training\n",
      "Epoch 1/100\n",
      "1230/1230 [==============================] - 103s 84ms/step - loss: 0.4957 - accuracy: 0.7809 - val_loss: 0.6966 - val_accuracy: 0.7590\n",
      "Epoch 2/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4939 - accuracy: 0.7819 - val_loss: 0.7416 - val_accuracy: 0.7626\n",
      "Epoch 3/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4938 - accuracy: 0.7826 - val_loss: 0.2742 - val_accuracy: 0.76270.4948  -\n",
      "Epoch 4/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4932 - accuracy: 0.7838 - val_loss: 0.3839 - val_accuracy: 0.7626\n",
      "Epoch 5/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4938 - accuracy: 0.7832 - val_loss: 0.6037 - val_accuracy: 0.7572\n",
      "Epoch 6/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4920 - accuracy: 0.7831 - val_loss: 0.4240 - val_accuracy: 0.7686\n",
      "Epoch 7/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4921 - accuracy: 0.7844 - val_loss: 0.4302 - val_accuracy: 0.7567\n",
      "Epoch 8/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4922 - accuracy: 0.7841 - val_loss: 0.4276 - val_accuracy: 0.7657\n",
      "Epoch 9/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4938 - accuracy: 0.7832 - val_loss: 0.5241 - val_accuracy: 0.7621\n",
      "Epoch 10/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4929 - accuracy: 0.7836 - val_loss: 0.4500 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4932 - accuracy: 0.7836 - val_loss: 0.5828 - val_accuracy: 0.7629\n",
      "Epoch 12/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4925 - accuracy: 0.7843 - val_loss: 0.3148 - val_accuracy: 0.7568\n",
      "Epoch 13/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4921 - accuracy: 0.7840 - val_loss: 0.2625 - val_accuracy: 0.7498\n",
      "Epoch 14/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4928 - accuracy: 0.7846 - val_loss: 0.2845 - val_accuracy: 0.7518\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4920 - accuracy: 0.7840 - val_loss: 0.5146 - val_accuracy: 0.7490\n",
      "Epoch 16/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4922 - accuracy: 0.7850 - val_loss: 0.6845 - val_accuracy: 0.7552\n",
      "Epoch 17/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4917 - accuracy: 0.7838 - val_loss: 0.5029 - val_accuracy: 0.7577\n",
      "Epoch 18/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4905 - accuracy: 0.7841 - val_loss: 0.5177 - val_accuracy: 0.7628\n",
      "Epoch 19/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4902 - accuracy: 0.7841 - val_loss: 0.5328 - val_accuracy: 0.7556\n",
      "Epoch 20/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4894 - accuracy: 0.7856 - val_loss: 0.5811 - val_accuracy: 0.7578\n",
      "Epoch 21/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4897 - accuracy: 0.7851 - val_loss: 0.6174 - val_accuracy: 0.7481\n",
      "Epoch 22/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4896 - accuracy: 0.7852 - val_loss: 0.6312 - val_accuracy: 0.7522\n",
      "Epoch 23/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4895 - accuracy: 0.7846 - val_loss: 0.5411 - val_accuracy: 0.7508\n",
      "Epoch 24/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4876 - accuracy: 0.7851 - val_loss: 0.5110 - val_accuracy: 0.7489\n",
      "Epoch 25/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4887 - accuracy: 0.7844 - val_loss: 0.2911 - val_accuracy: 0.7545\n",
      "Epoch 26/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4881 - accuracy: 0.7852 - val_loss: 0.3155 - val_accuracy: 0.7464\n",
      "Epoch 27/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4895 - accuracy: 0.7840 - val_loss: 0.3425 - val_accuracy: 0.7644ss: 0.4901 - accura\n",
      "Epoch 28/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4887 - accuracy: 0.7852 - val_loss: 0.6667 - val_accuracy: 0.7514\n",
      "Epoch 29/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4885 - accuracy: 0.7849 - val_loss: 0.3308 - val_accuracy: 0.7537\n",
      "Epoch 30/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4870 - accuracy: 0.7864 - val_loss: 0.8331 - val_accuracy: 0.7627\n",
      "Epoch 31/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4887 - accuracy: 0.7847 - val_loss: 0.2604 - val_accuracy: 0.7589\n",
      "Epoch 32/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4898 - accuracy: 0.7840 - val_loss: 0.5468 - val_accuracy: 0.7566\n",
      "Epoch 33/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4891 - accuracy: 0.7846 - val_loss: 1.2562 - val_accuracy: 0.7506\n",
      "Epoch 34/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4883 - accuracy: 0.7862 - val_loss: 1.9025 - val_accuracy: 0.7507\n",
      "Epoch 35/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4884 - accuracy: 0.7860 - val_loss: 0.3779 - val_accuracy: 0.7556\n",
      "Epoch 36/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4888 - accuracy: 0.7846 - val_loss: 0.4035 - val_accuracy: 0.7531\n",
      "Epoch 37/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7856 - val_loss: 0.5568 - val_accuracy: 0.7510 ETA: 46s - loss: 0.4877 - - ETA: 32s - loss: - ETA: 30s - ETA: 27s - l - ETA:  - ETA: 0s - loss: 0.487\n",
      "Epoch 38/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4893 - accuracy: 0.7850 - val_loss: 0.3173 - val_accuracy: 0.7510\n",
      "Epoch 39/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4880 - accuracy: 0.7852 - val_loss: 0.3168 - val_accuracy: 0.7489\n",
      "Epoch 40/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4875 - accuracy: 0.7852 - val_loss: 0.5451 - val_accuracy: 0.7483\n",
      "Epoch 41/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4873 - accuracy: 0.7856 - val_loss: 0.3321 - val_accuracy: 0.7567\n",
      "Epoch 42/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7845 - val_loss: 0.9139 - val_accuracy: 0.7559\n",
      "Epoch 43/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4888 - accuracy: 0.7835 - val_loss: 0.3840 - val_accuracy: 0.7450\n",
      "Epoch 44/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4869 - accuracy: 0.7849 - val_loss: 0.9813 - val_accuracy: 0.7417\n",
      "Epoch 45/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4881 - accuracy: 0.7852 - val_loss: 0.4647 - val_accuracy: 0.7309\n",
      "Epoch 46/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4864 - accuracy: 0.7860 - val_loss: 0.7010 - val_accuracy: 0.740766 -  - ETA:  - - ETA: 0s - loss: 0.4862 - \n",
      "Epoch 47/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4884 - accuracy: 0.7849 - val_loss: 1.1856 - val_accuracy: 0.7359\n",
      "Epoch 48/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4872 - accuracy: 0.7856 - val_loss: 1.1441 - val_accuracy: 0.7246\n",
      "Epoch 49/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4874 - accuracy: 0.7848 - val_loss: 0.7058 - val_accuracy: 0.7367\n",
      "Epoch 50/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4880 - accuracy: 0.7868 - val_loss: 0.7233 - val_accuracy: 0.7361\n",
      "Epoch 51/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4870 - accuracy: 0.7853 - val_loss: 0.5350 - val_accuracy: 0.7465\n",
      "Epoch 52/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7853 - val_loss: 0.7618 - val_accuracy: 0.7396\n",
      "Epoch 53/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4852 - accuracy: 0.7866 - val_loss: 0.6844 - val_accuracy: 0.7429\n",
      "Epoch 54/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4875 - accuracy: 0.7852 - val_loss: 0.3263 - val_accuracy: 0.7365\n",
      "Epoch 55/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4863 - accuracy: 0.7862 - val_loss: 0.3808 - val_accuracy: 0.7467\n",
      "Epoch 56/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4872 - accuracy: 0.7861 - val_loss: 0.6885 - val_accuracy: 0.7406\n",
      "Epoch 57/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4891 - accuracy: 0.7847 - val_loss: 0.6785 - val_accuracy: 0.7357\n",
      "Epoch 58/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4873 - accuracy: 0.7847 - val_loss: 0.6271 - val_accuracy: 0.7440\n",
      "Epoch 59/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4857 - accuracy: 0.7864 - val_loss: 0.5468 - val_accuracy: 0.7432\n",
      "Epoch 60/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4865 - accuracy: 0.7857 - val_loss: 0.5069 - val_accuracy: 0.7499\n",
      "Epoch 61/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4878 - accuracy: 0.7847 - val_loss: 0.6638 - val_accuracy: 0.7427\n",
      "Epoch 62/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4871 - accuracy: 0.7851 - val_loss: 0.8193 - val_accuracy: 0.7426\n",
      "Epoch 63/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4885 - accuracy: 0.7846 - val_loss: 1.0604 - val_accuracy: 0.7359\n",
      "Epoch 64/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4879 - accuracy: 0.7856 - val_loss: 0.9887 - val_accuracy: 0.7420\n",
      "Epoch 65/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7850 - val_loss: 1.0873 - val_accuracy: 0.7455\n",
      "Epoch 66/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4869 - accuracy: 0.7853 - val_loss: 0.8038 - val_accuracy: 0.7399\n",
      "Epoch 67/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4869 - accuracy: 0.7847 - val_loss: 1.1584 - val_accuracy: 0.7287loss: 0.4874 - accura\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4863 - accuracy: 0.7858 - val_loss: 0.8741 - val_accuracy: 0.7310\n",
      "Epoch 69/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4881 - accuracy: 0.7856 - val_loss: 1.0018 - val_accuracy: 0.7481 0s - loss: 0.4880 - accu\n",
      "Epoch 70/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4868 - accuracy: 0.7854 - val_loss: 1.1697 - val_accuracy: 0.7403A - ETA: 48s - l - - - ET - E - ETA: 2s - loss: 0.4882 - accuracy: 0. - ETA:  - ETA: 0s - loss: 0.4863 - accura - ETA: 0s - loss: 0.4867 - accuracy: \n",
      "Epoch 71/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7845 - val_loss: 0.7355 - val_accuracy: 0.7458\n",
      "Epoch 72/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4862 - accuracy: 0.7860 - val_loss: 0.4182 - val_accuracy: 0.7507\n",
      "Epoch 73/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4863 - accuracy: 0.7857 - val_loss: 0.5465 - val_accuracy: 0.7364\n",
      "Epoch 74/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4877 - accuracy: 0.7840 - val_loss: 0.1549 - val_accuracy: 0.7466\n",
      "Epoch 75/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4868 - accuracy: 0.7861 - val_loss: 0.1598 - val_accuracy: 0.7452\n",
      "Epoch 76/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4869 - accuracy: 0.7856 - val_loss: 0.2475 - val_accuracy: 0.7465\n",
      "Epoch 77/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4874 - accuracy: 0.7856 - val_loss: 0.2133 - val_accuracy: 0.7324\n",
      "Epoch 78/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4875 - accuracy: 0.7862 - val_loss: 0.2555 - val_accuracy: 0.7477\n",
      "Epoch 79/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4868 - accuracy: 0.7856 - val_loss: 0.5152 - val_accuracy: 0.7302\n",
      "Epoch 80/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4862 - accuracy: 0.7856 - val_loss: 0.2960 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4882 - accuracy: 0.7850 - val_loss: 0.2382 - val_accuracy: 0.7532\n",
      "Epoch 82/100\n",
      "1230/1230 [==============================] - 103s 84ms/step - loss: 0.4890 - accuracy: 0.7842 - val_loss: 0.0260 - val_accuracy: 0.7547\n",
      "Epoch 83/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4887 - accuracy: 0.7846 - val_loss: 0.1465 - val_accuracy: 0.75600.4896 - accuracy: 0. - ETA: 0s - loss: 0.4891 - \n",
      "Epoch 84/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4877 - accuracy: 0.7848 - val_loss: 0.2933 - val_accuracy: 0.7538s - loss: 0.4881 - ac\n",
      "Epoch 85/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4873 - accuracy: 0.7858 - val_loss: 0.3471 - val_accuracy: 0.7427\n",
      "Epoch 86/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4888 - accuracy: 0.7850 - val_loss: 0.2123 - val_accuracy: 0.7588\n",
      "Epoch 87/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4873 - accuracy: 0.7850 - val_loss: 0.6073 - val_accuracy: 0.7454\n",
      "Epoch 88/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4864 - accuracy: 0.7857 - val_loss: 0.3712 - val_accuracy: 0.7575\n",
      "Epoch 89/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4875 - accuracy: 0.7851 - val_loss: 0.4061 - val_accuracy: 0.7539\n",
      "Epoch 90/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4883 - accuracy: 0.7846 - val_loss: 0.5115 - val_accuracy: 0.7428\n",
      "Epoch 91/100\n",
      "1230/1230 [==============================] - 100s 81ms/step - loss: 0.4872 - accuracy: 0.7854 - val_loss: 0.3476 - val_accuracy: 0.7462\n",
      "Epoch 92/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4859 - accuracy: 0.7860 - val_loss: 0.9270 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4869 - accuracy: 0.7850 - val_loss: 0.6686 - val_accuracy: 0.7415\n",
      "Epoch 94/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4871 - accuracy: 0.7853 - val_loss: 0.6289 - val_accuracy: 0.7373\n",
      "Epoch 95/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4861 - accuracy: 0.7864 - val_loss: 0.5132 - val_accuracy: 0.7409loss: 0.4863 - accuracy: 0.78\n",
      "Epoch 96/100\n",
      "1230/1230 [==============================] - 99s 81ms/step - loss: 0.4862 - accuracy: 0.7853 - val_loss: 0.4102 - val_accuracy: 0.7427\n",
      "Epoch 97/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4878 - accuracy: 0.7844 - val_loss: 0.2767 - val_accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "1230/1230 [==============================] - 102s 83ms/step - loss: 0.4876 - accuracy: 0.7848 - val_loss: 0.4273 - val_accuracy: 0.7449\n",
      "Epoch 99/100\n",
      "1230/1230 [==============================] - 101s 82ms/step - loss: 0.4862 - accuracy: 0.7858 - val_loss: 0.5418 - val_accuracy: 0.7381\n",
      "Epoch 100/100\n",
      "1230/1230 [==============================] - 100s 82ms/step - loss: 0.4878 - accuracy: 0.7847 - val_loss: 0.3729 - val_accuracy: 0.7468\n",
      "Prediction on test data\n",
      "best epoch:  006\n",
      "Counting predicted:  Counter({1: 19267, 0: 1401})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7765\n",
      "Confusion matrix:\n",
      "[[  901  4120]\n",
      " [  500 15147]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.18      0.28      5021\n",
      "           1       0.79      0.97      0.87     15647\n",
      "\n",
      "    accuracy                           0.78     20668\n",
      "   macro avg       0.71      0.57      0.57     20668\n",
      "weighted avg       0.75      0.78      0.73     20668\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.696046\n",
      "Fold: 6\n",
      "Training\n",
      "Epoch 1/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.5037 - accuracy: 0.7766 - val_loss: 0.5185 - val_accuracy: 0.7716\n",
      "Epoch 2/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.5028 - accuracy: 0.7773 - val_loss: 0.5576 - val_accuracy: 0.7746\n",
      "Epoch 3/100\n",
      "1242/1242 [==============================] - 98s 79ms/step - loss: 0.5015 - accuracy: 0.7769 - val_loss: 0.6761 - val_accuracy: 0.7692\n",
      "Epoch 4/100\n",
      "1242/1242 [==============================] - 98s 79ms/step - loss: 0.5006 - accuracy: 0.7772 - val_loss: 0.5889 - val_accuracy: 0.7739\n",
      "Epoch 5/100\n",
      "1242/1242 [==============================] - 97s 78ms/step - loss: 0.4998 - accuracy: 0.7786 - val_loss: 0.5897 - val_accuracy: 0.7776A: 27s - loss: 0.5074 - accu - ETA: 26s -  - ETA: 24s - loss: 0. - ETA: 1s - loss: 0.5011 - ac - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.5001 - accuracy\n",
      "Epoch 6/100\n",
      "1242/1242 [==============================] - 96s 77ms/step - loss: 0.4988 - accuracy: 0.7790 - val_loss: 0.4517 - val_accuracy: 0.7727\n",
      "Epoch 7/100\n",
      "1242/1242 [==============================] - 97s 78ms/step - loss: 0.4986 - accuracy: 0.7774 - val_loss: 0.3026 - val_accuracy: 0.7752854 - accuracy:  - - ETA: 1:01 - l - ETA: 1:00 - loss: 0.48 - ETA: 59s - l\n",
      "Epoch 8/100\n",
      "1242/1242 [==============================] - 97s 78ms/step - loss: 0.4973 - accuracy: 0.7790 - val_loss: 0.4293 - val_accuracy: 0.7735 - loss: 0.4855 - accurac - ETA: 58s - loss: 0.4872 - accuracy:  - ETA: 57s - - ETA: - ETA: 49s - loss: 0.4970 - accurac - ETA: 49s - loss: 0.4990 - accuracy: 0.7 - E - ETA: 39s - loss: 0.4981 - accuracy: 0.7 - ETA: 39s - loss: 0.4970 - accu - ETA: 38s - loss: 0.4981 - accuracy: 0.7 - ETA: 37s - loss: 0.4988 - ac  - ETA: 33s - loss: 0.5052 - acc - ETA: 32s - loss: 0.5069 - accuracy: 0.77 - ETA: 32\n",
      "Epoch 9/100\n",
      "1242/1242 [==============================] - 96s 77ms/step - loss: 0.4992 - accuracy: 0.7792 - val_loss: 1.7472 - val_accuracy: 0.7721\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 97s 78ms/step - loss: 0.4996 - accuracy: 0.7783 - val_loss: 0.4560 - val_accuracy: 0.7744TA: 35s - loss: 0.5044 - accuracy: - ETA: 34s - loss: 0.5059 - accuracy: 0.772 - ETA: 34s - loss: 0.5062 - - ETA: 33s - l - ETA: 31s - loss: 0.5058 - - ETA: 30s - loss: 0 - ETA: 28s - loss: 0.5063 - accuracy: 0. - ETA: 27s  - ETA: 25 - E\n",
      "Epoch 11/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4975 - accuracy: 0.7796 - val_loss: 0.1911 - val_accuracy: 0.7731\n",
      "Epoch 12/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4978 - accuracy: 0.7789 - val_loss: 0.4527 - val_accuracy: 0.7734\n",
      "Epoch 13/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4972 - accuracy: 0.7791 - val_loss: 0.3882 - val_accuracy: 0.7702\n",
      "Epoch 14/100\n",
      "1242/1242 [==============================] - 99s 79ms/step - loss: 0.4962 - accuracy: 0.7790 - val_loss: 0.3949 - val_accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4971 - accuracy: 0.7799 - val_loss: 0.4183 - val_accuracy: 0.7730\n",
      "Epoch 16/100\n",
      "1242/1242 [==============================] - 98s 79ms/step - loss: 0.4964 - accuracy: 0.7801 - val_loss: 0.7613 - val_accuracy: 0.7727\n",
      "Epoch 17/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4957 - accuracy: 0.7799 - val_loss: 0.4866 - val_accuracy: 0.7744\n",
      "Epoch 18/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4953 - accuracy: 0.7801 - val_loss: 1.3409 - val_accuracy: 0.7764\n",
      "Epoch 19/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4962 - accuracy: 0.7803 - val_loss: 0.2750 - val_accuracy: 0.7760TA: 52s - loss: 0.4912 - acc - ETA: 51s - loss: 0.4913 - ETA: 50s - loss: 0.4959 - accu - ETA: 49s - ETA: 40s - loss: 0.4962 - accuracy - ETA: 39s - loss: 0.4945 - accuracy: 0.7 - ETA: 39s - lo\n",
      "Epoch 20/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4949 - accuracy: 0.7797 - val_loss: 0.7410 - val_accuracy: 0.7750 - ETA: 12s - \n",
      "Epoch 21/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4947 - accuracy: 0.7800 - val_loss: 0.6063 - val_accuracy: 0.7759\n",
      "Epoch 22/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4943 - accuracy: 0.7807 - val_loss: 0.2410 - val_accuracy: 0.7745- loss:  - ETA: 39s - loss: 0.4940 - - ETA: 0s - loss: 0.4953 - accuracy - ETA: 0s - loss: 0.4946 - accuracy: \n",
      "Epoch 23/100\n",
      "1242/1242 [==============================] - 99s 79ms/step - loss: 0.4947 - accuracy: 0.7800 - val_loss: 0.4595 - val_accuracy: 0.7744: 1s\n",
      "Epoch 24/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4943 - accuracy: 0.7799 - val_loss: 0.5959 - val_accuracy: 0.7756\n",
      "Epoch 25/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4943 - accuracy: 0.7797 - val_loss: 0.6571 - val_accuracy: 0.7759\n",
      "Epoch 26/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4940 - accuracy: 0.7819 - val_loss: 0.6528 - val_accuracy: 0.7761 - ETA: 0s - loss: 0.4940 - accuracy: \n",
      "Epoch 27/100\n",
      "1242/1242 [==============================] - 98s 79ms/step - loss: 0.4946 - accuracy: 0.7803 - val_loss: 0.6391 - val_accuracy: 0.7735os - ETA: 55s - loss: 0.4893 - accuracy: 0.7\n",
      "Epoch 28/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4939 - accuracy: 0.7814 - val_loss: 0.7270 - val_accuracy: 0.7759oss: - ETA: 0s - loss: 0.4942 - accuracy\n",
      "Epoch 29/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4939 - accuracy: 0.7804 - val_loss: 0.3673 - val_accuracy: 0.7748\n",
      "Epoch 30/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.4939 - accuracy: 0.7808 - val_loss: 0.4840 - val_accuracy: 0.76994902 - accuracy: 0.779 - ETA: 58s - loss: - ETA: 3s - loss: 0.4967  - ETA: 0s - loss: 0.4954 \n",
      "Epoch 31/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4943 - accuracy: 0.7804 - val_loss: 0.3272 - val_accuracy: 0.7757 loss: - - ETA: 1s - l\n",
      "Epoch 32/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4943 - accuracy: 0.7806 - val_loss: 0.4049 - val_accuracy: 0.7727\n",
      "Epoch 33/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4952 - accuracy: 0.7797 - val_loss: 0.3789 - val_accuracy: 0.7743\n",
      "Epoch 34/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4941 - accuracy: 0.7808 - val_loss: 0.3081 - val_accuracy: 0.77375s - loss: 0.5042 - accuracy: 0.77 - ETA: 25s - loss: 0.5042 - accuracy: 0.7 - ETA: 22s - loss: 0.5026 - accuracy: 0.7 - ETA - ETA: 2s - - ETA: 1s - loss: 0.4959 - ac - ETA: \n",
      "Epoch 35/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4937 - accuracy: 0.7817 - val_loss: 0.4959 - val_accuracy: 0.7718\n",
      "Epoch 36/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4936 - accuracy: 0.7808 - val_loss: 0.4171 - val_accuracy: 0.7766\n",
      "Epoch 37/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4941 - accuracy: 0.7812 - val_loss: 0.5264 - val_accuracy: 0.7758TA: 28s - loss: 0.5002  - ETA: 26s - loss: - ETA: 21s - loss - ETA: 8s - los - ETA: 7s - loss: 0 - ETA: 1s - loss: 0.4958 - accuracy:  - ETA: 0s - loss: 0.4958 - accura - ETA: 0s - loss: 0.4954 - \n",
      "Epoch 38/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4940 - accuracy: 0.7805 - val_loss: 0.4064 - val_accuracy: 0.7734: 0 - ETA: 56s -\n",
      "Epoch 39/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4922 - accuracy: 0.7818 - val_loss: 0.7858 - val_accuracy: 0.7718\n",
      "Epoch 40/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4939 - accuracy: 0.7813 - val_loss: 0.8157 - val_accuracy: 0.7735\n",
      "Epoch 41/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4932 - accuracy: 0.7815 - val_loss: 0.4977 - val_accuracy: 0.7703\n",
      "Epoch 42/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4933 - accuracy: 0.7810 - val_loss: 0.6373 - val_accuracy: 0.7743\n",
      "Epoch 43/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4931 - accuracy: 0.7818 - val_loss: 0.8278 - val_accuracy: 0.7737\n",
      "Epoch 44/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4929 - accuracy: 0.7818 - val_loss: 0.8457 - val_accuracy: 0.7696: 24s - loss: 0.5026 - accuracy: 0. - - ETA: 21s - loss: 0.4993 - accur - ETA: 20s  - ETA: 18s - loss: 0.5009 - - ETA: 13s -  - ETA: 11s - loss: 0.5002 - accuracy: 0.7 - ETA: 11s  - E - ETA: 7s - loss: 0.493 - ETA: 7s - loss: 0.4936  -\n",
      "Epoch 45/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4926 - accuracy: 0.7820 - val_loss: 1.1851 - val_accuracy: 0.7735\n",
      "Epoch 46/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4935 - accuracy: 0.7810 - val_loss: 1.2681 - val_accuracy: 0.7736\n",
      "Epoch 47/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4924 - accuracy: 0.7814 - val_loss: 1.4932 - val_accuracy: 0.7723\n",
      "Epoch 48/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4923 - accuracy: 0.7825 - val_loss: 0.7490 - val_accuracy: 0.7741\n",
      "Epoch 49/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4927 - accuracy: 0.7808 - val_loss: 1.1217 - val_accuracy: 0.7727\n",
      "Epoch 50/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4937 - accuracy: 0.7809 - val_loss: 0.7824 - val_accuracy: 0.7754\n",
      "Epoch 51/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4933 - accuracy: 0.7819 - val_loss: 1.1500 - val_accuracy: 0.7753\n",
      "Epoch 52/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4912 - accuracy: 0.7817 - val_loss: 1.4443 - val_accuracy: 0.7748\n",
      "Epoch 53/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4935 - accuracy: 0.7817 - val_loss: 0.4983 - val_accuracy: 0.7749\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4923 - accuracy: 0.7813 - val_loss: 0.2848 - val_accuracy: 0.7737accuracy: 0.77 - ETA: 45s - loss: 0.4924 - acc - ETA: 44s - loss: 0.4925 -  - ETA:  - ETA: 40s - loss: 0.4910 - accuracy: 0 - ETA: 39s - loss: 0.4904 - ac - ETA: 38s - loss: 0.4939 - acc - ETA:  - ETA: 35s - loss: 0.5003 - accuracy:  - ETA: 34s - loss: 0.5003 - accuracy: 0 - ETA: 34s - loss: 0.5012 - ETA: 32s -\n",
      "Epoch 55/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4925 - accuracy: 0.7818 - val_loss: 0.3636 - val_accuracy: 0.7757\n",
      "Epoch 56/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4948 - accuracy: 0.7803 - val_loss: 0.1567 - val_accuracy: 0.7725s - loss\n",
      "Epoch 57/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4927 - accuracy: 0.7825 - val_loss: 0.3734 - val_accuracy: 0.7735\n",
      "Epoch 58/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4925 - accuracy: 0.7819 - val_loss: 0.5272 - val_accuracy: 0.7724\n",
      "Epoch 59/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4913 - accuracy: 0.7827 - val_loss: 0.4074 - val_accuracy: 0.7694s - los - ETA: 1s - loss: 0.4932  - ETA: 1s\n",
      "Epoch 60/100\n",
      "1242/1242 [==============================] - 99s 79ms/step - loss: 0.4925 - accuracy: 0.7820 - val_loss: 0.8482 - val_accuracy: 0.77085034 - accuracy: 0. - ET - ETA: 20s - loss: 0.5003 - accuracy: - ETA: 19s -  - ETA: 3s - loss: 0.4 - ETA: 0s - los\n",
      "Epoch 61/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4937 - accuracy: 0.7807 - val_loss: 0.4647 - val_accuracy: 0.7713s: 0.4944 - ac\n",
      "Epoch 62/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4920 - accuracy: 0.7819 - val_loss: 0.9388 - val_accuracy: 0.7776\n",
      "Epoch 63/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4933 - accuracy: 0.7821 - val_loss: 0.9626 - val_accuracy: 0.7758\n",
      "Epoch 64/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4929 - accuracy: 0.7805 - val_loss: 0.2603 - val_accuracy: 0.7751:09 - loss: - E - ETA: 1:04 - loss: 0.4782  - ETA: 1:04 - loss: 0.4 - ETA: 1:03 - l - ETA: 36s - loss: 0.4984 - accuracy - E - ETA: 25s - loss: 0.5027 - acc - ETA: 20s - loss: 0.4996 - accu\n",
      "Epoch 65/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4932 - accuracy: 0.7824 - val_loss: 0.3853 - val_accuracy: 0.7715\n",
      "Epoch 66/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.4929 - accuracy: 0.7811 - val_loss: 0.4323 - val_accuracy: 0.7704u - E\n",
      "Epoch 67/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4911 - accuracy: 0.7838 - val_loss: 0.4285 - val_accuracy: 0.7751\n",
      "Epoch 68/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4910 - accuracy: 0.7829 - val_loss: 0.5890 - val_accuracy: 0.7727\n",
      "Epoch 69/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4920 - accuracy: 0.7818 - val_loss: 0.3564 - val_accuracy: 0.7743\n",
      "Epoch 70/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4920 - accuracy: 0.7819 - val_loss: 0.5454 - val_accuracy: 0.7710\n",
      "Epoch 71/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4917 - accuracy: 0.7813 - val_loss: 0.4408 - val_accuracy: 0.7716oss: 0.4974 - accuracy: 0.7 - ETA: 29s - los\n",
      "Epoch 72/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4919 - accuracy: 0.7822 - val_loss: 0.8713 - val_accuracy: 0.7742\n",
      "Epoch 73/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4923 - accuracy: 0.7807 - val_loss: 0.4575 - val_accuracy: 0.7776\n",
      "Epoch 74/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4920 - accuracy: 0.7825 - val_loss: 0.4936 - val_accuracy: 0.7730\n",
      "Epoch 75/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4921 - accuracy: 0.7818 - val_loss: 0.2870 - val_accuracy: 0.7743\n",
      "Epoch 76/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4910 - accuracy: 0.7818 - val_loss: 0.3627 - val_accuracy: 0.7730\n",
      "Epoch 77/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4913 - accuracy: 0.7821 - val_loss: 0.3393 - val_accuracy: 0.7700\n",
      "Epoch 78/100\n",
      "1242/1242 [==============================] - 99s 79ms/step - loss: 0.4913 - accuracy: 0.7816 - val_loss: 0.3276 - val_accuracy: 0.7743\n",
      "Epoch 79/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.4916 - accuracy: 0.7823 - val_loss: 0.3628 - val_accuracy: 0.7729\n",
      "Epoch 80/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4927 - accuracy: 0.7820 - val_loss: 0.3995 - val_accuracy: 0.7710\n",
      "Epoch 81/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4902 - accuracy: 0.7822 - val_loss: 0.3050 - val_accuracy: 0.7724\n",
      "Epoch 82/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.4916 - accuracy: 0.7819 - val_loss: 0.1250 - val_accuracy: 0.7731\n",
      "Epoch 83/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4927 - accuracy: 0.7810 - val_loss: 0.3483 - val_accuracy: 0.7747\n",
      "Epoch 84/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4914 - accuracy: 0.7820 - val_loss: 0.1121 - val_accuracy: 0.7741\n",
      "Epoch 85/100\n",
      "1242/1242 [==============================] - 98s 79ms/step - loss: 0.4928 - accuracy: 0.7809 - val_loss: 0.5273 - val_accuracy: 0.7697oss: 0.4946 - accuracy: - ETA: 44s - loss - ETA: 42s \n",
      "Epoch 86/100\n",
      "1242/1242 [==============================] - 101s 81ms/step - loss: 0.4914 - accuracy: 0.7813 - val_loss: 0.6197 - val_accuracy: 0.7739\n",
      "Epoch 87/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4917 - accuracy: 0.7817 - val_loss: 0.6595 - val_accuracy: 0.7684\n",
      "Epoch 88/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4932 - accuracy: 0.7817 - val_loss: 0.3442 - val_accuracy: 0.7764\n",
      "Epoch 89/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4911 - accuracy: 0.7819 - val_loss: 0.1907 - val_accuracy: 0.7716\n",
      "Epoch 90/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4918 - accuracy: 0.7806 - val_loss: 0.5885 - val_accuracy: 0.7755\n",
      "Epoch 91/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4917 - accuracy: 0.7814 - val_loss: 0.4346 - val_accuracy: 0.7747: 0.4935  - ETA: 0s - loss: 0.4930 \n",
      "Epoch 92/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4943 - accuracy: 0.7799 - val_loss: 0.7531 - val_accuracy: 0.77512 - accuracy: 0 - ETA: 50s - loss: 0.4938 - accuracy: 0.7 - ETA: 50s - loss:  - ETA: 35s - loss: 0.5015 - a - ETA: 33s - loss: 0.5031 - accuracy: 0.7 - ETA: 33s - loss: 0.5033 - accuracy: 0. - E\n",
      "Epoch 93/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4924 - accuracy: 0.7808 - val_loss: 0.5008 - val_accuracy: 0.7755\n",
      "Epoch 94/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4930 - accuracy: 0.7808 - val_loss: 0.5933 - val_accuracy: 0.7750\n",
      "Epoch 95/100\n",
      "1242/1242 [==============================] - 100s 80ms/step - loss: 0.4922 - accuracy: 0.7815 - val_loss: 0.6638 - val_accuracy: 0.7775 loss: 0.4940 - accuracy: 0 - ETA: 42s - loss: 0.4951 - accuracy - ETA: 41s - loss: 0.4954 - a - ETA: 40s - lo - ETA - ETA: 35s - loss:\n",
      "Epoch 96/100\n",
      "1242/1242 [==============================] - 99s 80ms/step - loss: 0.4926 - accuracy: 0.7803 - val_loss: 0.7456 - val_accuracy: 0.77550s - loss: 0.4985 - accuracy: 0.776 - ETA: 20s - ETA: 17s - loss: 0.5003 - accur - ETA: 16s - loss: 0.50 - ETA: 15s - lo\n",
      "Epoch 97/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4902 - accuracy: 0.7823 - val_loss: 0.4811 - val_accuracy: 0.7769\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 101s 82ms/step - loss: 0.4909 - accuracy: 0.7823 - val_loss: 0.5449 - val_accuracy: 0.77681 - ac - - E\n",
      "Epoch 99/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4917 - accuracy: 0.7819 - val_loss: 0.5017 - val_accuracy: 0.7773\n",
      "Epoch 100/100\n",
      "1242/1242 [==============================] - 100s 81ms/step - loss: 0.4920 - accuracy: 0.7814 - val_loss: 0.5336 - val_accuracy: 0.7774\n",
      "Prediction on test data\n",
      "best epoch:  005\n",
      "Counting predicted:  Counter({1: 18264, 0: 1941})\n",
      "\n",
      "Model Report\n",
      "Accuracy (test set): 0.7975\n",
      "Confusion matrix:\n",
      "[[  954  3105]\n",
      " [  987 15159]]\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.24      0.32      4059\n",
      "           1       0.83      0.94      0.88     16146\n",
      "\n",
      "    accuracy                           0.80     20205\n",
      "   macro avg       0.66      0.59      0.60     20205\n",
      "weighted avg       0.76      0.80      0.77     20205\n",
      "\n",
      "\n",
      "Model Report II part\n",
      "AUC Score (Test): 0.697260\n",
      "Fold: 7\n",
      "Training\n",
      "Epoch 1/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4982 - accuracy: 0.7811 - val_loss: 0.2979 - val_accuracy: 0.7889\n",
      "Epoch 2/100\n",
      "1235/1235 [==============================] - 101s 81ms/step - loss: 0.4957 - accuracy: 0.7804 - val_loss: 0.3317 - val_accuracy: 0.7895\n",
      "Epoch 3/100\n",
      "1235/1235 [==============================] - 98s 80ms/step - loss: 0.4949 - accuracy: 0.7808 - val_loss: 0.6714 - val_accuracy: 0.7893\n",
      "Epoch 4/100\n",
      "1235/1235 [==============================] - 98s 80ms/step - loss: 0.4948 - accuracy: 0.7818 - val_loss: 0.5522 - val_accuracy: 0.7831\n",
      "Epoch 5/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4944 - accuracy: 0.7818 - val_loss: 0.2840 - val_accuracy: 0.7847\n",
      "Epoch 6/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4934 - accuracy: 0.7823 - val_loss: 0.4300 - val_accuracy: 0.7873\n",
      "Epoch 7/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4932 - accuracy: 0.7824 - val_loss: 0.4354 - val_accuracy: 0.7824\n",
      "Epoch 8/100\n",
      "1235/1235 [==============================] - 98s 80ms/step - loss: 0.4930 - accuracy: 0.7821 - val_loss: 0.4825 - val_accuracy: 0.7811\n",
      "Epoch 9/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4925 - accuracy: 0.7828 - val_loss: 0.5710 - val_accuracy: 0.7836\n",
      "Epoch 10/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4924 - accuracy: 0.7819 - val_loss: 0.5659 - val_accuracy: 0.7878\n",
      "Epoch 11/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4914 - accuracy: 0.7837 - val_loss: 0.5565 - val_accuracy: 0.79094 - ETA: 15s - los - ETA: 13s - loss: 0.4944 - accuracy:  - ETA: 7s - los\n",
      "Epoch 12/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4903 - accuracy: 0.7835 - val_loss: 0.5554 - val_accuracy: 0.79031:02 - loss: 0.4 - ETA: 1:01  - ETA: 56s - loss: 0.4880 - accuracy: 0.7 - ETA: 56s - loss: - ETA: 54s - loss: 0.4825 - ETA: 53s - loss: - ETA: 51s - l - ETA: - E - ETA: 2s - ETA: 1s - l\n",
      "Epoch 13/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4928 - accuracy: 0.7830 - val_loss: 0.4391 - val_accuracy: 0.7934\n",
      "Epoch 14/100\n",
      "1235/1235 [==============================] - 98s 80ms/step - loss: 0.4913 - accuracy: 0.7833 - val_loss: 0.4559 - val_accuracy: 0.7897\n",
      "Epoch 15/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4935 - accuracy: 0.7823 - val_loss: 0.3889 - val_accuracy: 0.7890ura - ETA: 1:02 - l - ETA:  - ETA: 58\n",
      "Epoch 16/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4915 - accuracy: 0.7832 - val_loss: 0.5640 - val_accuracy: 0.7849\n",
      "Epoch 17/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4903 - accuracy: 0.7834 - val_loss: 1.4187 - val_accuracy: 0.7928\n",
      "Epoch 18/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4905 - accuracy: 0.7836 - val_loss: 0.2144 - val_accuracy: 0.7951\n",
      "Epoch 19/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4891 - accuracy: 0.7836 - val_loss: 0.2564 - val_accuracy: 0.7916\n",
      "Epoch 20/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4905 - accuracy: 0.7838 - val_loss: 0.6295 - val_accuracy: 0.7923\n",
      "Epoch 21/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4904 - accuracy: 0.7839 - val_loss: 0.5074 - val_accuracy: 0.7930\n",
      "Epoch 22/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4901 - accuracy: 0.7841 - val_loss: 0.4053 - val_accuracy: 0.7935\n",
      "Epoch 23/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4893 - accuracy: 0.7842 - val_loss: 0.6009 - val_accuracy: 0.7937\n",
      "Epoch 24/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4907 - accuracy: 0.7830 - val_loss: 0.4030 - val_accuracy: 0.7939\n",
      "Epoch 25/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4901 - accuracy: 0.7836 - val_loss: 0.5857 - val_accuracy: 0.79321s - - ETA: 2s - - ETA: 0s - loss: 0.4902 - accuracy: 0.\n",
      "Epoch 26/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4895 - accuracy: 0.7848 - val_loss: 0.1186 - val_accuracy: 0.7922\n",
      "Epoch 27/100\n",
      "1235/1235 [==============================] - 102s 82ms/step - loss: 0.4889 - accuracy: 0.7840 - val_loss: 0.1887 - val_accuracy: 0.7935\n",
      "Epoch 28/100\n",
      "1235/1235 [==============================] - 101s 81ms/step - loss: 0.4887 - accuracy: 0.7839 - val_loss: 0.3770 - val_accuracy: 0.7907\n",
      "Epoch 29/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4893 - accuracy: 0.7850 - val_loss: 0.3718 - val_accuracy: 0.7921\n",
      "Epoch 30/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4900 - accuracy: 0.7832 - val_loss: 1.4271 - val_accuracy: 0.7909\n",
      "Epoch 31/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4897 - accuracy: 0.7839 - val_loss: 1.7968 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7858 - val_loss: 1.0035 - val_accuracy: 0.7967\n",
      "Epoch 33/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4887 - accuracy: 0.7839 - val_loss: 0.3101 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4889 - accuracy: 0.7850 - val_loss: 0.2275 - val_accuracy: 0.7907\n",
      "Epoch 35/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4887 - accuracy: 0.7842 - val_loss: 0.2759 - val_accuracy: 0.7905\n",
      "Epoch 36/100\n",
      "1235/1235 [==============================] - 102s 82ms/step - loss: 0.4885 - accuracy: 0.7851 - val_loss: 0.1963 - val_accuracy: 0.7949\n",
      "Epoch 37/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4877 - accuracy: 0.7850 - val_loss: 0.6760 - val_accuracy: 0.7900\n",
      "Epoch 38/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4898 - accuracy: 0.7846 - val_loss: 0.2641 - val_accuracy: 0.7824\n",
      "Epoch 39/100\n",
      "1235/1235 [==============================] - 101s 82ms/step - loss: 0.4876 - accuracy: 0.7857 - val_loss: 0.4875 - val_accuracy: 0.7817\n",
      "Epoch 40/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4871 - accuracy: 0.7859 - val_loss: 0.5204 - val_accuracy: 0.7766\n",
      "Epoch 41/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4895 - accuracy: 0.7846 - val_loss: 0.6442 - val_accuracy: 0.7874\n",
      "Epoch 42/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4890 - accuracy: 0.7840 - val_loss: 0.6270 - val_accuracy: 0.7895\n",
      "Epoch 43/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4895 - accuracy: 0.7847 - val_loss: 0.3028 - val_accuracy: 0.7906\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4892 - accuracy: 0.7834 - val_loss: 0.8287 - val_accuracy: 0.7812: 35s - loss: 0.4907 - accuracy: 0.780 - ETA: 35s - loss: 0.4909 - accurac - ETA: 34s - loss: 0.4912 - accuracy: 0\n",
      "Epoch 45/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4891 - accuracy: 0.7837 - val_loss: 0.8675 - val_accuracy: 0.7926\n",
      "Epoch 46/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4889 - accuracy: 0.7844 - val_loss: 0.4531 - val_accuracy: 0.7888\n",
      "Epoch 47/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4890 - accuracy: 0.7843 - val_loss: 0.5702 - val_accuracy: 0.7857 l - ETA: 8s - los - ETA: 7s - loss: 0.4918 - accu - ETA: 0s - loss: 0.4887 - \n",
      "Epoch 48/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4871 - accuracy: 0.7840 - val_loss: 0.3870 - val_accuracy: 0.7889\n",
      "Epoch 49/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4862 - accuracy: 0.7849 - val_loss: 0.4443 - val_accuracy: 0.7834\n",
      "Epoch 50/100\n",
      "1235/1235 [==============================] - 100s 81ms/step - loss: 0.4885 - accuracy: 0.7859 - val_loss: 0.2495 - val_accuracy: 0.7798\n",
      "Epoch 51/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4874 - accuracy: 0.7851 - val_loss: 0.4479 - val_accuracy: 0.7805\n",
      "Epoch 52/100\n",
      "1235/1235 [==============================] - 99s 80ms/step - loss: 0.4863 - accuracy: 0.7857 - val_loss: 0.6844 - val_accuracy: 0.7801\n",
      "Epoch 53/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4872 - accuracy: 0.7856 - val_loss: 0.3823 - val_accuracy: 0.7854\n",
      "Epoch 54/100\n",
      "1235/1235 [==============================] - 102s 82ms/step - loss: 0.4869 - accuracy: 0.7867 - val_loss: 0.3806 - val_accuracy: 0.7737\n",
      "Epoch 55/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4875 - accuracy: 0.7849 - val_loss: 0.5371 - val_accuracy: 0.7819\n",
      "Epoch 56/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4847 - accuracy: 0.7857 - val_loss: 0.5229 - val_accuracy: 0.7706\n",
      "Epoch 57/100\n",
      "1235/1235 [==============================] - 102s 82ms/step - loss: 0.4869 - accuracy: 0.7851 - val_loss: 0.5691 - val_accuracy: 0.7566\n",
      "Epoch 58/100\n",
      "1235/1235 [==============================] - 102s 83ms/step - loss: 0.4871 - accuracy: 0.7851 - val_loss: 0.6905 - val_accuracy: 0.7662\n",
      "Epoch 59/100\n",
      "  84/1235 [=>............................] - ETA: 1:24 - loss: 0.4797 - accuracy: 0.7924"
     ]
    }
   ],
   "source": [
    "for fold in range(nfolds):\n",
    "#for fold in range(1):\n",
    "    print(\"Fold:\", str(fold))\n",
    "    file_list = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/splitting_lists/splitting_\",\n",
    "                               str(fold), \"_list.pickle\"))\n",
    "    with open(file_list, \"rb\") as input_file:\n",
    "        splitting_list = pickle.load(input_file)    \n",
    "    \n",
    "    splitting_list[0].sort()\n",
    "    splitting_list[1].sort()\n",
    "    #Defining generators\n",
    "    train_generator = batch_generator_DL(batch_size, f, group, table, splitting_list[0], \n",
    "                                     max_len_prot, type_padding_prot=type_padding_prot)\n",
    "    val_generator = batch_generator_DL(batch_size, f, group, table, splitting_list[1], \n",
    "                                     max_len_prot, type_padding_prot=type_padding_prot)\n",
    "    \n",
    "    #defining callbacks\n",
    "    if not os.path.exists(\"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/logs/\", str(fold), \"/\"))):\n",
    "        os.makedirs(\"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/logs/\", str(fold), \"/\")))\n",
    "    \n",
    "    log_path = \"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/logs/\", str(fold), \"/training_log.csv\"))\n",
    "    csv_logger = CSVLogger(log_path)\n",
    "\n",
    "    if not os.path.exists(\"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/checkpoint/\", str(fold), \"/\"))):\n",
    "        os.makedirs(\"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/checkpoint/\", str(fold), \"/\")))\n",
    "\n",
    "    #if there are already files in the folder, it removes them\n",
    "    r = glob(\"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/checkpoint/\", str(fold), \"/*\")))\n",
    "    for i in r:\n",
    "        os.remove(i)\n",
    "   \n",
    "    terminan = TerminateOnNaN()\n",
    "    checkpoint_path = \"\".join((absPath, \"data/\", protein_type, \n",
    "                                   \"/no_resampling/checkpoint/\", str(fold),\n",
    "                               \"/weights-improvement-{epoch:03d}-{val_accuracy:.4f}.hdf5\"))\n",
    "    mcheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, \n",
    "                                          save_best_only=True, save_weights_only=False)\n",
    "\n",
    "    callbacks_list = [csv_logger, terminan, mcheckpoint ]\n",
    "    print(\"Training\")\n",
    "    # fitting the model\n",
    "    history = model.fit_generator(generator=train_generator, \n",
    "                              validation_data=val_generator,\n",
    "                             steps_per_epoch= int(len(splitting_list[0])/batch_size),\n",
    "                              validation_steps=int(len(splitting_list[1])/batch_size),\n",
    "                             epochs=epochss,\n",
    "                             callbacks=callbacks_list,\n",
    "                             verbose=1)\n",
    "    #saving history\n",
    "    if not os.path.exists(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/\"))):\n",
    "        os.makedirs(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", str(fold), \"/\")))\n",
    "\n",
    "    with open(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", str(fold), \"/history.pickle\")), 'wb') as handle:\n",
    "        pickle.dump(history, handle)\n",
    "        \n",
    "    print(\"Prediction on test data\")\n",
    "    splitting_list[2].sort()\n",
    "    #PROTEINS\n",
    "    batch_sequences = list(f[group][table][splitting_list[2]][\"sequence\"])\n",
    "    #COMPOUNDS\n",
    "    batch_compounds = list(f[group][table][splitting_list[2]][\"fingerprint\"])\n",
    "    #LABELS\n",
    "    batch_y = list(f[group][table][splitting_list[2]][\"label\"])\n",
    "    #processing sequences and compounds\n",
    "    seqs_onehot = np.asarray(processing_sequences(batch_sequences, max_len_prot, type_padding_prot))\n",
    "    comps_batch = np.asarray(processing_fingerprints(batch_compounds))\n",
    "    batch_labels = np.asarray(bin_to_onehot(batch_y))\n",
    "    \n",
    "    history_path = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/history.pickle\"))\n",
    "    path_to_confusion = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/\"))\n",
    "    path_to_auc = \"\".join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/\"))\n",
    "    \n",
    "    history = plot_history(history_path, \"\".join((absPath, \"data/\", protein_type, \n",
    "                                                  \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/\")))\n",
    "    path_to_cp = ''.join((absPath, \"data/\", protein_type, \"/no_resampling/checkpoint/\", \n",
    "                          str(fold), \"/\"))\n",
    "\n",
    "    model, best_path = load_best_model(history, path_to_cp)\n",
    "\n",
    "    cps_loc = ''.join((absPath, \"data/\", protein_type, \"/no_resampling/checkpoint/\", \n",
    "                          str(fold), \"/*.hdf5\")) \n",
    "\n",
    "    #removing the rest of weights\n",
    "    fileList = glob(cps_loc, recursive=True)\n",
    "    fileList.remove(best_path)\n",
    "    if len(fileList) >1:\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except OSError:\n",
    "                print(\"Error while deleting file\")\n",
    "    \n",
    "    y_predprob = model.predict([seqs_onehot, comps_batch])\n",
    "    y_prob = y_predprob[:,1]\n",
    "    y_pred = y_predprob.argmax(-1)\n",
    "    y_test = batch_labels.argmax(-1)\n",
    "    print(\"Counting predicted: \", Counter(y_pred))\n",
    "    \n",
    "    batch_compID_test = list(f[group][table][splitting_list[2]][\"da_comp_id\"])\n",
    "    batch_protID_test = list(f[group][table][splitting_list[2]][\"da_prot_id\"])\n",
    "    \n",
    "    #confusion matrix\n",
    "    confusion_matrix(y_test, y_pred, path_to_confusion)\n",
    "        \n",
    "    #AUC\n",
    "    file_auc = ''.join((absPath, \"data/\", protein_type, \"/no_resampling/results/\", \n",
    "                                   str(fold), \"/AUC.pickle\"))\n",
    "    compute_roc(y_test, y_prob, path_to_auc)\n",
    "    \n",
    "    # saving predictions on test set\n",
    "\n",
    "    predictions_test = pd.DataFrame({\"y_test\":y_test, \"y_prob\":y_prob, \"y_pred\":y_pred, \"comp_ID\": batch_compID_test,\n",
    "                                \"DeepAffinity Protein ID\": batch_protID_test})\n",
    "\n",
    "    if not os.path.exists(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/predictions/\", str(fold), \"/\"))):\n",
    "        os.makedirs(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/predictions/\", str(fold), \"/\")))\n",
    "\n",
    "    predictions_test.to_csv(\"\".join((absPath, \"data/\", protein_type, \"/no_resampling/predictions/\", str(fold), \"/test.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
